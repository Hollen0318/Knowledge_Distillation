{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6H_dU4IZ8yM"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt4PH36gL9Eo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "import argparse\n",
        "import time\n",
        "import itertools\n",
        "from copy import deepcopy\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fedbPTuOMbq",
        "outputId": "adf58666-07a3-468b-b888-f2c8388627f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "fast_device = device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ys41LrdZEuQ"
      },
      "outputs": [],
      "source": [
        "checkpoints_path_teacher = 'checkpoints_teacher/'\n",
        "checkpoints_path_student = 'checkpoints_student/'\n",
        "if not os.path.exists(checkpoints_path_student):\n",
        "    os.makedirs(checkpoints_path_student)\n",
        "if not os.path.exists(checkpoints_path_teacher):\n",
        "    os.makedirs(checkpoints_path_teacher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT_AG_ch5TlX"
      },
      "source": [
        "# Utils Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep7q01Qx5SyF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "def trainStep(network, criterion, optimizer, X, y):\n",
        "\t\"\"\"\n",
        "\tOne training step of the network: forward prop + backprop + update parameters\n",
        "\tReturn: (loss, accuracy) of current batch\n",
        "\t\"\"\"\n",
        "\toptimizer.zero_grad()\n",
        "\toutputs = network(X)\n",
        "\tloss = criterion(outputs, y)\n",
        "\tloss.backward()\n",
        "\toptimizer.step()\n",
        "\taccuracy = float(torch.sum(torch.argmax(outputs, dim=1) == y).item()) / y.shape[0]\n",
        "\treturn loss, accuracy\n",
        "\n",
        "def getLossAccuracyOnDataset(network, dataset_loader, fast_device, criterion=None):\n",
        "\t\"\"\"\n",
        "\tReturns (loss, accuracy) of network on given dataset\n",
        "\t\"\"\"\n",
        "\tnetwork.is_training = False\n",
        "\taccuracy = 0.0\n",
        "\tloss = 0.0\n",
        "\tdataset_size = 0\n",
        "\tfor j, D in enumerate(dataset_loader, 0):\n",
        "\t\tX, y = D\n",
        "\t\tX = X.to(fast_device)\n",
        "\t\ty = y.to(fast_device)\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tpred = network(X)\n",
        "\t\t\tif criterion is not None:\n",
        "\t\t\t\tloss += criterion(pred, y) * y.shape[0]\n",
        "\t\t\taccuracy += torch.sum(torch.argmax(pred, dim=1) == y).item()\n",
        "\t\tdataset_size += y.shape[0]\n",
        "\tloss, accuracy = loss / dataset_size, accuracy / dataset_size\n",
        "\tnetwork.is_training = True\n",
        "\treturn loss, accuracy\n",
        "\n",
        "def trainTeacherOnHparam(teacher_net, hparam, num_epochs, \n",
        "\t\t\t\t\t\ttrain_loader, val_loader, \n",
        "\t\t\t\t\t\tprint_every=0, \n",
        "\t\t\t\t\t\tfast_device='cuda:0'):\n",
        "\t\"\"\"\n",
        "\tTrains teacher on given hyperparameters for given number of epochs; Pass val_loader=None when not required to validate for every epoch \n",
        "\tReturn: List of training loss, accuracy for each update calculated only on the batch; List of validation loss, accuracy for each epoch\n",
        "\t\"\"\"\n",
        "\ttrain_loss_list, train_acc_list, val_loss_list, val_acc_list = [], [], [], []\n",
        "\tteacher_net.dropout_input = hparam['dropout_input']\n",
        "\tteacher_net.dropout_hidden = hparam['dropout_hidden']\n",
        "\tcriterion = nn.CrossEntropyLoss()\n",
        "\toptimizer = optim.SGD(teacher_net.parameters(), lr=hparam['lr'], momentum=hparam['momentum'], weight_decay=hparam['weight_decay'])\n",
        "\tlr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=hparam['lr_decay'])\n",
        "\tfor epoch in range(num_epochs):\n",
        "\t\tlr_scheduler.step()\n",
        "\t\tif epoch == 0:\n",
        "\t\t\tif val_loader is not None:\n",
        "\t\t\t\tval_loss, val_acc = getLossAccuracyOnDataset(teacher_net, val_loader, fast_device, criterion)\n",
        "\t\t\t\tval_loss_list.append(val_loss)\n",
        "\t\t\t\tval_acc_list.append(val_acc)\n",
        "\t\t\t\tprint('epoch: %d validation loss: %.3f validation accuracy: %.3f' %(epoch, val_loss, val_acc))\n",
        "\t\tfor i, data in enumerate(train_loader, 0):\n",
        "\t\t\tX, y = data\n",
        "\t\t\tX, y = X.to(fast_device), y.to(fast_device)\n",
        "\t\t\tloss, acc = trainStep(teacher_net, criterion, optimizer, X, y)\n",
        "\t\t\ttrain_loss_list.append(loss)\n",
        "\t\t\ttrain_acc_list.append(acc)\n",
        "\t\t\n",
        "\t\t\tif print_every > 0 and i % print_every == print_every - 1:\n",
        "\t\t\t\tprint('[%d, %5d/%5d] train loss: %.3f train accuracy: %.3f' %\n",
        "\t\t\t\t\t  (epoch + 1, i + 1, len(train_loader), loss, acc))\n",
        "\t\t\n",
        "\t\tif val_loader is not None:\n",
        "\t\t\tval_loss, val_acc = getLossAccuracyOnDataset(teacher_net, val_loader, fast_device, criterion)\n",
        "\t\t\tval_loss_list.append(val_loss)\n",
        "\t\t\tval_acc_list.append(val_acc)\n",
        "\t\t\tprint('epoch: %d validation loss: %.3f validation accuracy: %.3f' %(epoch + 1, val_loss, val_acc))\n",
        "\treturn {'train_loss': train_loss_list, \n",
        "\t\t\t'train_acc': train_acc_list, \n",
        "\t\t\t'val_loss': val_loss_list, \n",
        "\t\t\t'val_acc': val_acc_list}\n",
        "\n",
        "def studentTrainStep(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha):\n",
        "\t\"\"\"\n",
        "\tOne training step of student network: forward prop + backprop + update parameters\n",
        "\tReturn: (loss, accuracy) of current batch\n",
        "\t\"\"\"\n",
        "\toptimizer.zero_grad()\n",
        "\tteacher_pred = None\n",
        "\tif (alpha > 0):\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tteacher_pred = teacher_net(X)\n",
        "\tstudent_pred = student_net(X)\n",
        "\tloss = studentLossFn(teacher_pred, student_pred, y, T, alpha)\n",
        "\tloss.backward()\n",
        "\toptimizer.step()\n",
        "\taccuracy = float(torch.sum(torch.argmax(student_pred, dim=1) == y).item()) / y.shape[0]\n",
        "\treturn loss, accuracy\n",
        "\n",
        "def trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "\t\t\t\t\t\ttrain_loader, val_loader, \n",
        "\t\t\t\t\t\tprint_every=0, \n",
        "\t\t\t\t\t\tfast_device=torch.device('cpu')):\n",
        "\t\"\"\"\n",
        "\tTrains teacher on given hyperparameters for given number of epochs; Pass val_loader=None when not required to validate for every epoch\n",
        "\tReturn: List of training loss, accuracy for each update calculated only on the batch; List of validation loss, accuracy for each epoch\n",
        "\t\"\"\"\n",
        "\ttrain_loss_list, train_acc_list, val_acc_list = [], [], []\n",
        "\tT = hparam['T']\n",
        "\talpha = hparam['alpha']\n",
        "\tstudent_net.dropout_input = hparam['dropout_input']\n",
        "\tstudent_net.dropout_hidden = hparam['dropout_hidden']\n",
        "\toptimizer = optim.SGD(student_net.parameters(), lr=hparam['lr'], momentum=hparam['momentum'], weight_decay=hparam['weight_decay'])\n",
        "\tlr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=hparam['lr_decay'])\n",
        "\n",
        "\tdef studentLossFn(teacher_pred, student_pred, y, T, alpha):\n",
        "\t\t\"\"\"\n",
        "\t\tLoss function for student network: Loss = alpha * (distillation loss with soft-target) + (1 - alpha) * (cross-entropy loss with true label)\n",
        "\t\tReturn: loss\n",
        "\t\t\"\"\"\n",
        "\t\tif (alpha > 0):\n",
        "\t\t\tloss = F.kl_div(F.log_softmax(student_pred / T, dim=1), F.softmax(teacher_pred / T, dim=1), reduction='batchmean') * (T ** 2) * alpha + F.cross_entropy(student_pred, y) * (1 - alpha)\n",
        "\t\telse:\n",
        "\t\t\tloss = F.cross_entropy(student_pred, y)\n",
        "\t\treturn loss\n",
        "\n",
        "\tfor epoch in range(num_epochs):\n",
        "\t\tlr_scheduler.step()\n",
        "\t\tif epoch == 0:\n",
        "\t\t\tif val_loader is not None:\n",
        "\t\t\t\t_, val_acc = getLossAccuracyOnDataset(student_net, val_loader, fast_device)\n",
        "\t\t\t\tval_acc_list.append(val_acc)\n",
        "\t\t\t\tprint('epoch: %d validation accuracy: %.3f' %(epoch, val_acc))\n",
        "\t\tfor i, data in enumerate(train_loader, 0):\n",
        "\t\t\tX, y = data\n",
        "\t\t\tX, y = X.to(fast_device), y.to(fast_device)\n",
        "\t\t\tloss, acc = studentTrainStep(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha)\n",
        "\t\t\ttrain_loss_list.append(loss)\n",
        "\t\t\ttrain_acc_list.append(acc)\n",
        "\t\t\n",
        "\t\t\tif print_every > 0 and i % print_every == print_every - 1:\n",
        "\t\t\t\tprint('[%d, %5d/%5d] train loss: %.3f train accuracy: %.3f' %\n",
        "\t\t\t\t\t  (epoch + 1, i + 1, len(train_loader), loss, acc))\n",
        "\t\n",
        "\t\tif val_loader is not None:\n",
        "\t\t\t_, val_acc = getLossAccuracyOnDataset(student_net, val_loader, fast_device)\n",
        "\t\t\tval_acc_list.append(val_acc)\n",
        "\t\t\tprint('epoch: %d validation accuracy: %.3f' %(epoch + 1, val_acc))\n",
        "\treturn {'train_loss': train_loss_list, \n",
        "\t\t\t'train_acc': train_acc_list, \n",
        "\t\t\t'val_acc': val_acc_list}\n",
        "\n",
        "def hparamToString(hparam):\n",
        "\t\"\"\"\n",
        "\tConvert hparam dictionary to string with deterministic order of attribute of hparam in output string\n",
        "\t\"\"\"\n",
        "\thparam_str = ''\n",
        "\tfor k, v in sorted(hparam.items()):\n",
        "\t\thparam_str += k + '=' + str(v) + ', '\n",
        "\treturn hparam_str[:-2]\n",
        "\n",
        "def hparamDictToTuple(hparam):\n",
        "\t\"\"\"\n",
        "\tConvert hparam dictionary to tuple with deterministic order of attribute of hparam in output tuple\n",
        "\t\"\"\"\n",
        "\thparam_tuple = [v for k, v in sorted(hparam.items())]\n",
        "\treturn tuple(hparam_tuple)\n",
        "\n",
        "def getTrainMetricPerEpoch(train_metric, updates_per_epoch):\n",
        "\t\"\"\"\n",
        "\tSmooth the training metric calculated for each batch of training set by averaging over batches in an epoch\n",
        "\tInput: List of training metric calculated for each batch\n",
        "\tOutput: List of training matric averaged over each epoch\n",
        "\t\"\"\"\n",
        "\ttrain_metric_per_epoch = []\n",
        "\ttemp_sum = 0.0\n",
        "\tfor i in range(len(train_metric)):\n",
        "\t\ttemp_sum += train_metric[i]\n",
        "\t\tif (i % updates_per_epoch == updates_per_epoch - 1):\n",
        "\t\t\ttrain_metric_per_epoch.append(temp_sum / updates_per_epoch)\n",
        "\t\t\ttemp_sum = 0.0\n",
        "\n",
        "\treturn train_metric_per_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqYCpNY1piD4"
      },
      "source": [
        "# Observe FLOPS and Number of Parameter function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luy_Jf-aplzg"
      },
      "outputs": [],
      "source": [
        "def print_the_model_out(net):\n",
        "  for name, module in net.named_modules():\n",
        "    # print(name, module)\n",
        "    if isinstance(module, nn.Linear):\n",
        "      # Get the input feature map of the module as a NumPy array\n",
        "      input = module.input.cpu().detach().numpy()     #Your code here\n",
        "      # Get the output feature map of the module as a NumPy array\n",
        "      output = module.output.cpu().detach().numpy()     #Your code here\n",
        "      # Get the weight of the module as a NumPy array\n",
        "      weight = module.weight     #Your code here\n",
        "      num_Param = torch.numel(weight)\n",
        "      num_MAC = input.shape[1]*output.shape[1]\n",
        "      print(f'{name:10} {str(input.shape):20} {str(output.shape):20} {str(weight.shape):20} {str(num_Param):10} {str(num_MAC):10}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIrYpWa2aB1r"
      },
      "source": [
        "# ReproducibilitySeed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKB4rDlzXoh3"
      },
      "outputs": [],
      "source": [
        "def reproducibilitySeed():\n",
        "    \"\"\"\n",
        "    Ensure reproducibility of results; Seeds to 0\n",
        "    \"\"\"\n",
        "    torch_init_seed = 0\n",
        "    torch.manual_seed(torch_init_seed)\n",
        "    numpy_init_seed = 0\n",
        "    np.random.seed(numpy_init_seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reproducibilitySeed()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjfMOiqoaGXH"
      },
      "source": [
        "# Student & Teacher Network Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2dh6sB1EqiA"
      },
      "outputs": [],
      "source": [
        "class FC(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "        super(FC, self).__init__(in_features, out_features, bias)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        self.output = F.linear(input, self.weight, self.bias)\n",
        "        return self.output\n",
        "\n",
        "class TeacherNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TeacherNetwork, self).__init__()\n",
        "        self.fc1 = FC(28 * 28, 1200)\n",
        "        self.fc2 = FC(1200, 1200)\n",
        "        self.fc3 = FC(1200, 10)\n",
        "        self.dropout_input = 0.2\n",
        "        self.dropout_hidden = 0.5\n",
        "        self.is_training = True\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.dropout(x, p=self.dropout_input, training=self.is_training)\n",
        "        x = F.dropout(F.relu(self.fc1(x)), p=self.dropout_hidden, training=self.is_training)\n",
        "        x = F.dropout(F.relu(self.fc2(x)), p=self.dropout_hidden, training=self.is_training)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class StudentNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StudentNetwork, self).__init__()\n",
        "        self.fc1 = FC(28 * 28, 400)\n",
        "        self.fc2 = FC(400, 10)\n",
        "        self.dropout_input = 0.0\n",
        "        self.dropout_hidden = 0.0\n",
        "        self.is_training = True\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.dropout(x, p=self.dropout_input, training=self.is_training)\n",
        "        x = F.dropout(F.relu(self.fc1(x)), p=self.dropout_hidden, training=self.is_training)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class StudentNetworkSmall(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StudentNetworkSmall, self).__init__()\n",
        "        self.fc1 = FC(28 * 28, 30)\n",
        "        self.fc2 = FC(30, 10)\n",
        "        self.dropout_input = 0.0\n",
        "        self.dropout_hidden = 0.0\n",
        "        self.is_training = True\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.dropout(x, p=self.dropout_input, training=self.is_training)\n",
        "        x = F.dropout(F.relu(self.fc1(x)), p=self.dropout_hidden, training=self.is_training)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60fK42rvaMgH"
      },
      "source": [
        "# Teacher dataloader with Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "8IIpnBg_XsEp",
        "outputId": "3a909cb5-bf65-4aff-bf74-a7a04e22b000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST_dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d32e898112a4e33831a9a9f847f453e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_dataset/MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST_dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST_dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b35bea7cb284d1da8958b6329890b86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST_dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba5c983178a94cb287ca59ada5564e1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST_dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49684efbd59e4e86a08aa1c691be9e52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST_dataset/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "mnist_image_shape = (28, 28)\n",
        "random_pad_size = 2\n",
        "# Training images augmented by randomly shifting images by at max. 2 pixels in any of 4 directions\n",
        "transform_train = transforms.Compose(\n",
        "                [\n",
        "                    transforms.RandomCrop(mnist_image_shape, random_pad_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.5], [0.5])\n",
        "                ]\n",
        "            )\n",
        "\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    # transforms.Normalize((0.5, 0.5), (0.5, 0.5))\n",
        "                    transforms.Normalize([0.5], [0.5])\n",
        "                ]\n",
        "            )\n",
        "\n",
        "train_val_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=True, \n",
        "                                            download=True, transform=transform_train)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=False, \n",
        "                                            download=True, transform=transform_test)\n",
        "\n",
        "num_train = int(1.0 * len(train_val_dataset) * 95 / 100)\n",
        "num_val = len(train_val_dataset) - num_train\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
        "\n",
        "batch_size = 128\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HXQ9Iu1abae"
      },
      "source": [
        "# Peek at Teacher & Student Network Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYFuRXv8L6Jx",
        "outputId": "6ebe3bba-3542-471c-a575-a96fd5418952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TeacherNetwork(\n",
            "  (fc1): FC(in_features=784, out_features=1200, bias=True)\n",
            "  (fc2): FC(in_features=1200, out_features=1200, bias=True)\n",
            "  (fc3): FC(in_features=1200, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "teacher_net = TeacherNetwork().to(device)\n",
        "print(teacher_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3wv95JaNP3R",
        "outputId": "a39e69a3-4063-44ac-b6a8-c226dda8731d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StudentNetwork(\n",
            "  (fc1): FC(in_features=784, out_features=400, bias=True)\n",
            "  (fc2): FC(in_features=400, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "student_net = StudentNetwork().to(device)\n",
        "print(student_net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbgMENMOagyY"
      },
      "source": [
        "# Train Teacher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJGcxQr3ZJwY"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60\n",
        "print_every = 100    # Interval size for which to print statistics of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrOm318OOiZM",
        "outputId": "d4330fd5-4404-4755-d494-9e3c98bd0b71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100/  469] train loss: 0.979 train accuracy: 0.672\n",
            "[1,   200/  469] train loss: 0.686 train accuracy: 0.781\n",
            "[1,   300/  469] train loss: 0.771 train accuracy: 0.781\n",
            "[1,   400/  469] train loss: 0.437 train accuracy: 0.867\n",
            "[2,   100/  469] train loss: 0.246 train accuracy: 0.914\n",
            "[2,   200/  469] train loss: 0.260 train accuracy: 0.914\n",
            "[2,   300/  469] train loss: 0.409 train accuracy: 0.883\n",
            "[2,   400/  469] train loss: 0.264 train accuracy: 0.930\n",
            "[3,   100/  469] train loss: 0.196 train accuracy: 0.922\n",
            "[3,   200/  469] train loss: 0.125 train accuracy: 0.977\n",
            "[3,   300/  469] train loss: 0.187 train accuracy: 0.945\n",
            "[3,   400/  469] train loss: 0.148 train accuracy: 0.969\n",
            "[4,   100/  469] train loss: 0.210 train accuracy: 0.945\n",
            "[4,   200/  469] train loss: 0.155 train accuracy: 0.938\n",
            "[4,   300/  469] train loss: 0.080 train accuracy: 0.977\n",
            "[4,   400/  469] train loss: 0.179 train accuracy: 0.938\n",
            "[5,   100/  469] train loss: 0.181 train accuracy: 0.938\n",
            "[5,   200/  469] train loss: 0.190 train accuracy: 0.938\n",
            "[5,   300/  469] train loss: 0.102 train accuracy: 0.977\n",
            "[5,   400/  469] train loss: 0.108 train accuracy: 0.961\n",
            "[6,   100/  469] train loss: 0.093 train accuracy: 0.961\n",
            "[6,   200/  469] train loss: 0.119 train accuracy: 0.984\n",
            "[6,   300/  469] train loss: 0.129 train accuracy: 0.984\n",
            "[6,   400/  469] train loss: 0.136 train accuracy: 0.961\n",
            "[7,   100/  469] train loss: 0.169 train accuracy: 0.945\n",
            "[7,   200/  469] train loss: 0.156 train accuracy: 0.938\n",
            "[7,   300/  469] train loss: 0.239 train accuracy: 0.930\n",
            "[7,   400/  469] train loss: 0.151 train accuracy: 0.953\n",
            "[8,   100/  469] train loss: 0.107 train accuracy: 0.961\n",
            "[8,   200/  469] train loss: 0.136 train accuracy: 0.953\n",
            "[8,   300/  469] train loss: 0.112 train accuracy: 0.953\n",
            "[8,   400/  469] train loss: 0.054 train accuracy: 0.984\n",
            "[9,   100/  469] train loss: 0.096 train accuracy: 0.984\n",
            "[9,   200/  469] train loss: 0.126 train accuracy: 0.969\n",
            "[9,   300/  469] train loss: 0.042 train accuracy: 0.984\n",
            "[9,   400/  469] train loss: 0.073 train accuracy: 0.977\n",
            "[10,   100/  469] train loss: 0.063 train accuracy: 0.984\n",
            "[10,   200/  469] train loss: 0.105 train accuracy: 0.961\n",
            "[10,   300/  469] train loss: 0.048 train accuracy: 0.992\n",
            "[10,   400/  469] train loss: 0.061 train accuracy: 0.969\n",
            "[11,   100/  469] train loss: 0.029 train accuracy: 1.000\n",
            "[11,   200/  469] train loss: 0.099 train accuracy: 0.961\n",
            "[11,   300/  469] train loss: 0.082 train accuracy: 0.969\n",
            "[11,   400/  469] train loss: 0.056 train accuracy: 0.984\n",
            "[12,   100/  469] train loss: 0.178 train accuracy: 0.953\n",
            "[12,   200/  469] train loss: 0.069 train accuracy: 0.977\n",
            "[12,   300/  469] train loss: 0.049 train accuracy: 0.977\n",
            "[12,   400/  469] train loss: 0.088 train accuracy: 0.961\n",
            "[13,   100/  469] train loss: 0.126 train accuracy: 0.961\n",
            "[13,   200/  469] train loss: 0.074 train accuracy: 0.977\n",
            "[13,   300/  469] train loss: 0.030 train accuracy: 0.992\n",
            "[13,   400/  469] train loss: 0.095 train accuracy: 0.961\n",
            "[14,   100/  469] train loss: 0.179 train accuracy: 0.945\n",
            "[14,   200/  469] train loss: 0.047 train accuracy: 0.969\n",
            "[14,   300/  469] train loss: 0.094 train accuracy: 0.984\n",
            "[14,   400/  469] train loss: 0.094 train accuracy: 0.977\n",
            "[15,   100/  469] train loss: 0.072 train accuracy: 0.984\n",
            "[15,   200/  469] train loss: 0.065 train accuracy: 0.977\n",
            "[15,   300/  469] train loss: 0.081 train accuracy: 0.977\n",
            "[15,   400/  469] train loss: 0.063 train accuracy: 0.977\n",
            "[16,   100/  469] train loss: 0.086 train accuracy: 0.969\n",
            "[16,   200/  469] train loss: 0.033 train accuracy: 0.992\n",
            "[16,   300/  469] train loss: 0.039 train accuracy: 0.977\n",
            "[16,   400/  469] train loss: 0.065 train accuracy: 0.992\n",
            "[17,   100/  469] train loss: 0.080 train accuracy: 0.977\n",
            "[17,   200/  469] train loss: 0.077 train accuracy: 0.984\n",
            "[17,   300/  469] train loss: 0.039 train accuracy: 0.984\n",
            "[17,   400/  469] train loss: 0.046 train accuracy: 0.984\n",
            "[18,   100/  469] train loss: 0.033 train accuracy: 0.992\n",
            "[18,   200/  469] train loss: 0.029 train accuracy: 0.984\n",
            "[18,   300/  469] train loss: 0.044 train accuracy: 0.984\n",
            "[18,   400/  469] train loss: 0.041 train accuracy: 0.977\n",
            "[19,   100/  469] train loss: 0.055 train accuracy: 0.977\n",
            "[19,   200/  469] train loss: 0.016 train accuracy: 1.000\n",
            "[19,   300/  469] train loss: 0.103 train accuracy: 0.961\n",
            "[19,   400/  469] train loss: 0.041 train accuracy: 0.992\n",
            "[20,   100/  469] train loss: 0.061 train accuracy: 0.984\n",
            "[20,   200/  469] train loss: 0.119 train accuracy: 0.969\n",
            "[20,   300/  469] train loss: 0.026 train accuracy: 0.992\n",
            "[20,   400/  469] train loss: 0.081 train accuracy: 0.977\n",
            "[21,   100/  469] train loss: 0.044 train accuracy: 0.984\n",
            "[21,   200/  469] train loss: 0.131 train accuracy: 0.969\n",
            "[21,   300/  469] train loss: 0.049 train accuracy: 0.977\n",
            "[21,   400/  469] train loss: 0.083 train accuracy: 0.984\n",
            "[22,   100/  469] train loss: 0.065 train accuracy: 0.977\n",
            "[22,   200/  469] train loss: 0.057 train accuracy: 0.984\n",
            "[22,   300/  469] train loss: 0.028 train accuracy: 0.992\n",
            "[22,   400/  469] train loss: 0.018 train accuracy: 1.000\n",
            "[23,   100/  469] train loss: 0.034 train accuracy: 0.984\n",
            "[23,   200/  469] train loss: 0.062 train accuracy: 0.977\n",
            "[23,   300/  469] train loss: 0.056 train accuracy: 0.969\n",
            "[23,   400/  469] train loss: 0.070 train accuracy: 0.977\n",
            "[24,   100/  469] train loss: 0.067 train accuracy: 0.953\n",
            "[24,   200/  469] train loss: 0.181 train accuracy: 0.977\n",
            "[24,   300/  469] train loss: 0.035 train accuracy: 0.984\n",
            "[24,   400/  469] train loss: 0.090 train accuracy: 0.977\n",
            "[25,   100/  469] train loss: 0.068 train accuracy: 0.977\n",
            "[25,   200/  469] train loss: 0.028 train accuracy: 0.992\n",
            "[25,   300/  469] train loss: 0.085 train accuracy: 0.969\n",
            "[25,   400/  469] train loss: 0.068 train accuracy: 0.984\n",
            "[26,   100/  469] train loss: 0.020 train accuracy: 0.992\n",
            "[26,   200/  469] train loss: 0.066 train accuracy: 0.984\n",
            "[26,   300/  469] train loss: 0.063 train accuracy: 0.977\n",
            "[26,   400/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[27,   100/  469] train loss: 0.025 train accuracy: 0.992\n",
            "[27,   200/  469] train loss: 0.045 train accuracy: 0.984\n",
            "[27,   300/  469] train loss: 0.030 train accuracy: 0.992\n",
            "[27,   400/  469] train loss: 0.048 train accuracy: 0.977\n",
            "[28,   100/  469] train loss: 0.042 train accuracy: 0.984\n",
            "[28,   200/  469] train loss: 0.021 train accuracy: 0.992\n",
            "[28,   300/  469] train loss: 0.122 train accuracy: 0.961\n",
            "[28,   400/  469] train loss: 0.092 train accuracy: 0.977\n",
            "[29,   100/  469] train loss: 0.042 train accuracy: 0.992\n",
            "[29,   200/  469] train loss: 0.020 train accuracy: 0.992\n",
            "[29,   300/  469] train loss: 0.052 train accuracy: 0.984\n",
            "[29,   400/  469] train loss: 0.023 train accuracy: 0.992\n",
            "[30,   100/  469] train loss: 0.067 train accuracy: 0.984\n",
            "[30,   200/  469] train loss: 0.087 train accuracy: 0.984\n",
            "[30,   300/  469] train loss: 0.018 train accuracy: 1.000\n",
            "[30,   400/  469] train loss: 0.026 train accuracy: 0.992\n",
            "[31,   100/  469] train loss: 0.035 train accuracy: 0.984\n",
            "[31,   200/  469] train loss: 0.064 train accuracy: 0.977\n",
            "[31,   300/  469] train loss: 0.042 train accuracy: 0.984\n",
            "[31,   400/  469] train loss: 0.091 train accuracy: 0.977\n",
            "[32,   100/  469] train loss: 0.009 train accuracy: 1.000\n",
            "[32,   200/  469] train loss: 0.027 train accuracy: 0.992\n",
            "[32,   300/  469] train loss: 0.102 train accuracy: 0.984\n",
            "[32,   400/  469] train loss: 0.015 train accuracy: 0.992\n",
            "[33,   100/  469] train loss: 0.114 train accuracy: 0.938\n",
            "[33,   200/  469] train loss: 0.057 train accuracy: 0.969\n",
            "[33,   300/  469] train loss: 0.048 train accuracy: 0.984\n",
            "[33,   400/  469] train loss: 0.025 train accuracy: 0.992\n",
            "[34,   100/  469] train loss: 0.041 train accuracy: 0.992\n",
            "[34,   200/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[34,   300/  469] train loss: 0.079 train accuracy: 0.969\n",
            "[34,   400/  469] train loss: 0.025 train accuracy: 1.000\n",
            "[35,   100/  469] train loss: 0.075 train accuracy: 0.977\n",
            "[35,   200/  469] train loss: 0.096 train accuracy: 0.953\n",
            "[35,   300/  469] train loss: 0.043 train accuracy: 0.977\n",
            "[35,   400/  469] train loss: 0.028 train accuracy: 0.992\n",
            "[36,   100/  469] train loss: 0.026 train accuracy: 0.992\n",
            "[36,   200/  469] train loss: 0.021 train accuracy: 1.000\n",
            "[36,   300/  469] train loss: 0.057 train accuracy: 0.977\n",
            "[36,   400/  469] train loss: 0.061 train accuracy: 0.984\n",
            "[37,   100/  469] train loss: 0.027 train accuracy: 0.992\n",
            "[37,   200/  469] train loss: 0.029 train accuracy: 0.984\n",
            "[37,   300/  469] train loss: 0.075 train accuracy: 0.992\n",
            "[37,   400/  469] train loss: 0.074 train accuracy: 0.984\n",
            "[38,   100/  469] train loss: 0.038 train accuracy: 0.984\n",
            "[38,   200/  469] train loss: 0.017 train accuracy: 1.000\n",
            "[38,   300/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[38,   400/  469] train loss: 0.020 train accuracy: 0.992\n",
            "[39,   100/  469] train loss: 0.043 train accuracy: 0.977\n",
            "[39,   200/  469] train loss: 0.026 train accuracy: 0.992\n",
            "[39,   300/  469] train loss: 0.025 train accuracy: 1.000\n",
            "[39,   400/  469] train loss: 0.042 train accuracy: 0.984\n",
            "[40,   100/  469] train loss: 0.056 train accuracy: 0.984\n",
            "[40,   200/  469] train loss: 0.053 train accuracy: 0.977\n",
            "[40,   300/  469] train loss: 0.077 train accuracy: 0.969\n",
            "[40,   400/  469] train loss: 0.047 train accuracy: 0.984\n",
            "[41,   100/  469] train loss: 0.042 train accuracy: 0.984\n",
            "[41,   200/  469] train loss: 0.034 train accuracy: 0.992\n",
            "[41,   300/  469] train loss: 0.053 train accuracy: 0.984\n",
            "[41,   400/  469] train loss: 0.039 train accuracy: 0.984\n",
            "[42,   100/  469] train loss: 0.085 train accuracy: 0.977\n",
            "[42,   200/  469] train loss: 0.025 train accuracy: 0.992\n",
            "[42,   300/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[42,   400/  469] train loss: 0.073 train accuracy: 0.969\n",
            "[43,   100/  469] train loss: 0.019 train accuracy: 1.000\n",
            "[43,   200/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[43,   300/  469] train loss: 0.040 train accuracy: 0.984\n",
            "[43,   400/  469] train loss: 0.007 train accuracy: 1.000\n",
            "[44,   100/  469] train loss: 0.016 train accuracy: 0.992\n",
            "[44,   200/  469] train loss: 0.046 train accuracy: 0.992\n",
            "[44,   300/  469] train loss: 0.099 train accuracy: 0.984\n",
            "[44,   400/  469] train loss: 0.020 train accuracy: 1.000\n",
            "[45,   100/  469] train loss: 0.068 train accuracy: 0.969\n",
            "[45,   200/  469] train loss: 0.021 train accuracy: 0.984\n",
            "[45,   300/  469] train loss: 0.039 train accuracy: 0.984\n",
            "[45,   400/  469] train loss: 0.081 train accuracy: 0.969\n",
            "[46,   100/  469] train loss: 0.023 train accuracy: 0.992\n",
            "[46,   200/  469] train loss: 0.091 train accuracy: 0.969\n",
            "[46,   300/  469] train loss: 0.023 train accuracy: 0.984\n",
            "[46,   400/  469] train loss: 0.065 train accuracy: 0.984\n",
            "[47,   100/  469] train loss: 0.021 train accuracy: 0.992\n",
            "[47,   200/  469] train loss: 0.027 train accuracy: 0.992\n",
            "[47,   300/  469] train loss: 0.054 train accuracy: 0.977\n",
            "[47,   400/  469] train loss: 0.035 train accuracy: 0.984\n",
            "[48,   100/  469] train loss: 0.063 train accuracy: 0.984\n",
            "[48,   200/  469] train loss: 0.008 train accuracy: 1.000\n",
            "[48,   300/  469] train loss: 0.035 train accuracy: 0.984\n",
            "[48,   400/  469] train loss: 0.068 train accuracy: 0.984\n",
            "[49,   100/  469] train loss: 0.003 train accuracy: 1.000\n",
            "[49,   200/  469] train loss: 0.029 train accuracy: 0.984\n",
            "[49,   300/  469] train loss: 0.019 train accuracy: 0.992\n",
            "[49,   400/  469] train loss: 0.057 train accuracy: 0.984\n",
            "[50,   100/  469] train loss: 0.035 train accuracy: 0.984\n",
            "[50,   200/  469] train loss: 0.088 train accuracy: 0.977\n",
            "[50,   300/  469] train loss: 0.012 train accuracy: 1.000\n",
            "[50,   400/  469] train loss: 0.031 train accuracy: 0.984\n",
            "[51,   100/  469] train loss: 0.033 train accuracy: 0.992\n",
            "[51,   200/  469] train loss: 0.068 train accuracy: 0.977\n",
            "[51,   300/  469] train loss: 0.022 train accuracy: 0.992\n",
            "[51,   400/  469] train loss: 0.012 train accuracy: 1.000\n",
            "[52,   100/  469] train loss: 0.061 train accuracy: 0.984\n",
            "[52,   200/  469] train loss: 0.015 train accuracy: 1.000\n",
            "[52,   300/  469] train loss: 0.026 train accuracy: 0.984\n",
            "[52,   400/  469] train loss: 0.020 train accuracy: 1.000\n",
            "[53,   100/  469] train loss: 0.022 train accuracy: 0.992\n",
            "[53,   200/  469] train loss: 0.050 train accuracy: 0.984\n",
            "[53,   300/  469] train loss: 0.023 train accuracy: 0.992\n",
            "[53,   400/  469] train loss: 0.059 train accuracy: 0.977\n",
            "[54,   100/  469] train loss: 0.020 train accuracy: 0.992\n",
            "[54,   200/  469] train loss: 0.010 train accuracy: 0.992\n",
            "[54,   300/  469] train loss: 0.028 train accuracy: 1.000\n",
            "[54,   400/  469] train loss: 0.050 train accuracy: 0.984\n",
            "[55,   100/  469] train loss: 0.042 train accuracy: 0.984\n",
            "[55,   200/  469] train loss: 0.036 train accuracy: 0.984\n",
            "[55,   300/  469] train loss: 0.048 train accuracy: 0.984\n",
            "[55,   400/  469] train loss: 0.018 train accuracy: 0.992\n",
            "[56,   100/  469] train loss: 0.034 train accuracy: 0.984\n",
            "[56,   200/  469] train loss: 0.180 train accuracy: 0.953\n",
            "[56,   300/  469] train loss: 0.043 train accuracy: 0.984\n",
            "[56,   400/  469] train loss: 0.022 train accuracy: 0.992\n",
            "[57,   100/  469] train loss: 0.044 train accuracy: 0.984\n",
            "[57,   200/  469] train loss: 0.137 train accuracy: 0.969\n",
            "[57,   300/  469] train loss: 0.008 train accuracy: 1.000\n",
            "[57,   400/  469] train loss: 0.042 train accuracy: 0.984\n",
            "[58,   100/  469] train loss: 0.032 train accuracy: 0.977\n",
            "[58,   200/  469] train loss: 0.024 train accuracy: 0.992\n",
            "[58,   300/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[58,   400/  469] train loss: 0.008 train accuracy: 1.000\n",
            "[59,   100/  469] train loss: 0.071 train accuracy: 0.977\n",
            "[59,   200/  469] train loss: 0.007 train accuracy: 1.000\n",
            "[59,   300/  469] train loss: 0.034 train accuracy: 0.984\n",
            "[59,   400/  469] train loss: 0.026 train accuracy: 1.000\n",
            "[60,   100/  469] train loss: 0.017 train accuracy: 0.992\n",
            "[60,   200/  469] train loss: 0.039 train accuracy: 0.984\n",
            "[60,   300/  469] train loss: 0.027 train accuracy: 0.992\n",
            "[60,   400/  469] train loss: 0.035 train accuracy: 0.992\n"
          ]
        }
      ],
      "source": [
        "# Hyperparamters can be tuned by setting required range below\n",
        "# learning_rates = list(np.logspace(-4, -2, 3))\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]    # learning rate decays at every epoch\n",
        "# weight_decays = [0.0] + list(np.logspace(-5, -1, 5))\n",
        "weight_decays = [1e-5]           # regularization weight\n",
        "momentums = [0.9]\n",
        "# dropout_probabilities = [(0.2, 0.5), (0.0, 0.0)]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['dropout_input'] = hparam_tuple[0][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[0][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[1]\n",
        "    hparam['lr_decay'] = hparam_tuple[2]\n",
        "    hparam['momentum'] = hparam_tuple[3]\n",
        "    hparam['lr'] = hparam_tuple[4]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    teacher_net = TeacherNetwork()\n",
        "    teacher_net = teacher_net.to(fast_device)\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results[hparam_tuple] = trainTeacherOnHparam(teacher_net, hparam, num_epochs, \n",
        "                                                        train_val_loader, None, \n",
        "                                                        print_every=print_every, \n",
        "                                                        fast_device=fast_device)\n",
        "    save_path = checkpoints_path_teacher + hparamToString(hparam) + '_final.tar'\n",
        "    torch.save({'results' : results[hparam_tuple], \n",
        "                'model_state_dict' : teacher_net.state_dict(), \n",
        "                'epoch' : num_epochs}, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r06JG661a-44"
      },
      "source": [
        "# Load Teacher Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVZMw9DEa0eV"
      },
      "outputs": [],
      "source": [
        "# set the hparams used for training teacher to load the teacher network\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "# keeping dropout input = dropout hidden\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['dropout_input'] = hparam_tuple[0][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[0][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[1]\n",
        "    hparam['lr_decay'] = hparam_tuple[2]\n",
        "    hparam['momentum'] = hparam_tuple[3]\n",
        "    hparam['lr'] = hparam_tuple[4]\n",
        "    hparams_list.append(hparam)\n",
        "    \n",
        "load_path = checkpoints_path_teacher + hparamToString(hparams_list[0]) + '_final.tar'\n",
        "teacher_net = TeacherNetwork()\n",
        "teacher_net.load_state_dict(torch.load(load_path, map_location=fast_device)['model_state_dict'])\n",
        "teacher_net = teacher_net.to(fast_device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OGeihmzbCIS"
      },
      "source": [
        "## Calculate the Teacher accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZRttCbmbAT5"
      },
      "outputs": [],
      "source": [
        "# Calculate teacher test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n",
        "print('teacher test accuracy: ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKVMNxRjZz-G"
      },
      "source": [
        "# Student dataloader without data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knoPDf8TZ6uj"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Student trained without data augmentation\n",
        "transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.5], [0.5])\n",
        "                ]\n",
        "            )\n",
        "\n",
        "train_val_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=True, \n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=False, \n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "num_train = int(1.0 * len(train_val_dataset) * 95 / 100)\n",
        "num_val = len(train_val_dataset) - num_train\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
        "\n",
        "batch_size = 128\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S1btnKMbH08"
      },
      "source": [
        "# Train student network without distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u65caoxGbEpW"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60\n",
        "print_every = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8-_ZNqobLPq",
        "outputId": "9dc14fca-de32-4be6-a861-ce023f278e40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=1, alpha=0.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
            "[1,   100/  469] train loss: 0.336 train accuracy: 0.906\n",
            "[1,   200/  469] train loss: 0.495 train accuracy: 0.859\n",
            "[1,   300/  469] train loss: 0.259 train accuracy: 0.891\n",
            "[1,   400/  469] train loss: 0.249 train accuracy: 0.906\n",
            "[2,   100/  469] train loss: 0.180 train accuracy: 0.938\n",
            "[2,   200/  469] train loss: 0.204 train accuracy: 0.969\n",
            "[2,   300/  469] train loss: 0.278 train accuracy: 0.891\n",
            "[2,   400/  469] train loss: 0.286 train accuracy: 0.938\n",
            "[3,   100/  469] train loss: 0.074 train accuracy: 0.984\n",
            "[3,   200/  469] train loss: 0.110 train accuracy: 0.961\n",
            "[3,   300/  469] train loss: 0.251 train accuracy: 0.922\n",
            "[3,   400/  469] train loss: 0.175 train accuracy: 0.953\n",
            "[4,   100/  469] train loss: 0.187 train accuracy: 0.945\n",
            "[4,   200/  469] train loss: 0.218 train accuracy: 0.914\n",
            "[4,   300/  469] train loss: 0.086 train accuracy: 0.977\n",
            "[4,   400/  469] train loss: 0.118 train accuracy: 0.969\n",
            "[5,   100/  469] train loss: 0.142 train accuracy: 0.953\n",
            "[5,   200/  469] train loss: 0.094 train accuracy: 0.984\n",
            "[5,   300/  469] train loss: 0.140 train accuracy: 0.961\n",
            "[5,   400/  469] train loss: 0.071 train accuracy: 0.984\n",
            "[6,   100/  469] train loss: 0.066 train accuracy: 0.992\n",
            "[6,   200/  469] train loss: 0.155 train accuracy: 0.961\n",
            "[6,   300/  469] train loss: 0.140 train accuracy: 0.969\n",
            "[6,   400/  469] train loss: 0.097 train accuracy: 0.969\n",
            "[7,   100/  469] train loss: 0.132 train accuracy: 0.969\n",
            "[7,   200/  469] train loss: 0.060 train accuracy: 0.977\n",
            "[7,   300/  469] train loss: 0.079 train accuracy: 0.992\n",
            "[7,   400/  469] train loss: 0.091 train accuracy: 0.977\n",
            "[8,   100/  469] train loss: 0.049 train accuracy: 0.992\n",
            "[8,   200/  469] train loss: 0.069 train accuracy: 0.977\n",
            "[8,   300/  469] train loss: 0.043 train accuracy: 1.000\n",
            "[8,   400/  469] train loss: 0.094 train accuracy: 0.977\n",
            "[9,   100/  469] train loss: 0.057 train accuracy: 0.992\n",
            "[9,   200/  469] train loss: 0.040 train accuracy: 0.984\n",
            "[9,   300/  469] train loss: 0.095 train accuracy: 0.961\n",
            "[9,   400/  469] train loss: 0.039 train accuracy: 0.984\n",
            "[10,   100/  469] train loss: 0.172 train accuracy: 0.953\n",
            "[10,   200/  469] train loss: 0.086 train accuracy: 0.977\n",
            "[10,   300/  469] train loss: 0.089 train accuracy: 0.977\n",
            "[10,   400/  469] train loss: 0.095 train accuracy: 0.969\n",
            "[11,   100/  469] train loss: 0.084 train accuracy: 0.984\n",
            "[11,   200/  469] train loss: 0.043 train accuracy: 0.992\n",
            "[11,   300/  469] train loss: 0.028 train accuracy: 1.000\n",
            "[11,   400/  469] train loss: 0.051 train accuracy: 0.984\n",
            "[12,   100/  469] train loss: 0.060 train accuracy: 0.977\n",
            "[12,   200/  469] train loss: 0.045 train accuracy: 0.984\n",
            "[12,   300/  469] train loss: 0.022 train accuracy: 0.992\n",
            "[12,   400/  469] train loss: 0.029 train accuracy: 1.000\n",
            "[13,   100/  469] train loss: 0.048 train accuracy: 0.984\n",
            "[13,   200/  469] train loss: 0.056 train accuracy: 0.977\n",
            "[13,   300/  469] train loss: 0.038 train accuracy: 0.977\n",
            "[13,   400/  469] train loss: 0.074 train accuracy: 0.969\n",
            "[14,   100/  469] train loss: 0.133 train accuracy: 0.961\n",
            "[14,   200/  469] train loss: 0.039 train accuracy: 0.977\n",
            "[14,   300/  469] train loss: 0.066 train accuracy: 0.992\n",
            "[14,   400/  469] train loss: 0.075 train accuracy: 0.969\n",
            "[15,   100/  469] train loss: 0.026 train accuracy: 1.000\n",
            "[15,   200/  469] train loss: 0.024 train accuracy: 0.992\n",
            "[15,   300/  469] train loss: 0.016 train accuracy: 1.000\n",
            "[15,   400/  469] train loss: 0.047 train accuracy: 0.977\n",
            "[16,   100/  469] train loss: 0.073 train accuracy: 0.984\n",
            "[16,   200/  469] train loss: 0.028 train accuracy: 1.000\n",
            "[16,   300/  469] train loss: 0.060 train accuracy: 0.984\n",
            "[16,   400/  469] train loss: 0.043 train accuracy: 0.977\n",
            "[17,   100/  469] train loss: 0.043 train accuracy: 0.977\n",
            "[17,   200/  469] train loss: 0.030 train accuracy: 0.992\n",
            "[17,   300/  469] train loss: 0.054 train accuracy: 0.984\n",
            "[17,   400/  469] train loss: 0.050 train accuracy: 0.984\n",
            "[18,   100/  469] train loss: 0.089 train accuracy: 0.977\n",
            "[18,   200/  469] train loss: 0.025 train accuracy: 0.992\n",
            "[18,   300/  469] train loss: 0.063 train accuracy: 0.992\n",
            "[18,   400/  469] train loss: 0.029 train accuracy: 1.000\n",
            "[19,   100/  469] train loss: 0.050 train accuracy: 0.977\n",
            "[19,   200/  469] train loss: 0.020 train accuracy: 1.000\n",
            "[19,   300/  469] train loss: 0.035 train accuracy: 0.992\n",
            "[19,   400/  469] train loss: 0.039 train accuracy: 0.992\n",
            "[20,   100/  469] train loss: 0.009 train accuracy: 1.000\n",
            "[20,   200/  469] train loss: 0.020 train accuracy: 0.992\n",
            "[20,   300/  469] train loss: 0.040 train accuracy: 0.992\n",
            "[20,   400/  469] train loss: 0.029 train accuracy: 0.992\n",
            "[21,   100/  469] train loss: 0.016 train accuracy: 1.000\n",
            "[21,   200/  469] train loss: 0.018 train accuracy: 1.000\n",
            "[21,   300/  469] train loss: 0.030 train accuracy: 0.992\n",
            "[21,   400/  469] train loss: 0.020 train accuracy: 0.992\n",
            "[22,   100/  469] train loss: 0.038 train accuracy: 1.000\n",
            "[22,   200/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[22,   300/  469] train loss: 0.028 train accuracy: 0.992\n",
            "[22,   400/  469] train loss: 0.011 train accuracy: 1.000\n",
            "[23,   100/  469] train loss: 0.023 train accuracy: 1.000\n",
            "[23,   200/  469] train loss: 0.027 train accuracy: 0.984\n",
            "[23,   300/  469] train loss: 0.017 train accuracy: 1.000\n",
            "[23,   400/  469] train loss: 0.035 train accuracy: 0.984\n",
            "[24,   100/  469] train loss: 0.021 train accuracy: 1.000\n",
            "[24,   200/  469] train loss: 0.026 train accuracy: 1.000\n",
            "[24,   300/  469] train loss: 0.047 train accuracy: 0.984\n",
            "[24,   400/  469] train loss: 0.011 train accuracy: 1.000\n",
            "[25,   100/  469] train loss: 0.019 train accuracy: 1.000\n",
            "[25,   200/  469] train loss: 0.019 train accuracy: 1.000\n",
            "[25,   300/  469] train loss: 0.021 train accuracy: 1.000\n",
            "[25,   400/  469] train loss: 0.018 train accuracy: 1.000\n",
            "[26,   100/  469] train loss: 0.016 train accuracy: 1.000\n",
            "[26,   200/  469] train loss: 0.017 train accuracy: 1.000\n",
            "[26,   300/  469] train loss: 0.015 train accuracy: 1.000\n",
            "[26,   400/  469] train loss: 0.022 train accuracy: 1.000\n",
            "[27,   100/  469] train loss: 0.040 train accuracy: 0.992\n",
            "[27,   200/  469] train loss: 0.022 train accuracy: 1.000\n",
            "[27,   300/  469] train loss: 0.022 train accuracy: 1.000\n",
            "[27,   400/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[28,   100/  469] train loss: 0.027 train accuracy: 0.992\n",
            "[28,   200/  469] train loss: 0.042 train accuracy: 0.992\n",
            "[28,   300/  469] train loss: 0.072 train accuracy: 0.984\n",
            "[28,   400/  469] train loss: 0.044 train accuracy: 1.000\n",
            "[29,   100/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[29,   200/  469] train loss: 0.023 train accuracy: 1.000\n",
            "[29,   300/  469] train loss: 0.012 train accuracy: 1.000\n",
            "[29,   400/  469] train loss: 0.028 train accuracy: 0.984\n",
            "[30,   100/  469] train loss: 0.043 train accuracy: 0.992\n",
            "[30,   200/  469] train loss: 0.010 train accuracy: 1.000\n",
            "[30,   300/  469] train loss: 0.051 train accuracy: 0.992\n",
            "[30,   400/  469] train loss: 0.025 train accuracy: 1.000\n",
            "[31,   100/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[31,   200/  469] train loss: 0.015 train accuracy: 1.000\n",
            "[31,   300/  469] train loss: 0.011 train accuracy: 1.000\n",
            "[31,   400/  469] train loss: 0.029 train accuracy: 0.992\n",
            "[32,   100/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[32,   200/  469] train loss: 0.035 train accuracy: 0.992\n",
            "[32,   300/  469] train loss: 0.015 train accuracy: 1.000\n",
            "[32,   400/  469] train loss: 0.106 train accuracy: 0.992\n",
            "[33,   100/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[33,   200/  469] train loss: 0.023 train accuracy: 0.992\n",
            "[33,   300/  469] train loss: 0.061 train accuracy: 0.992\n",
            "[33,   400/  469] train loss: 0.026 train accuracy: 0.992\n",
            "[34,   100/  469] train loss: 0.018 train accuracy: 1.000\n",
            "[34,   200/  469] train loss: 0.017 train accuracy: 1.000\n",
            "[34,   300/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[34,   400/  469] train loss: 0.031 train accuracy: 0.992\n",
            "[35,   100/  469] train loss: 0.015 train accuracy: 1.000\n",
            "[35,   200/  469] train loss: 0.019 train accuracy: 1.000\n",
            "[35,   300/  469] train loss: 0.020 train accuracy: 1.000\n",
            "[35,   400/  469] train loss: 0.019 train accuracy: 1.000\n",
            "[36,   100/  469] train loss: 0.015 train accuracy: 1.000\n",
            "[36,   200/  469] train loss: 0.091 train accuracy: 0.984\n",
            "[36,   300/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[36,   400/  469] train loss: 0.028 train accuracy: 0.992\n",
            "[37,   100/  469] train loss: 0.032 train accuracy: 0.992\n",
            "[37,   200/  469] train loss: 0.019 train accuracy: 1.000\n",
            "[37,   300/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[37,   400/  469] train loss: 0.017 train accuracy: 1.000\n",
            "[38,   100/  469] train loss: 0.015 train accuracy: 1.000\n",
            "[38,   200/  469] train loss: 0.041 train accuracy: 0.977\n",
            "[38,   300/  469] train loss: 0.019 train accuracy: 1.000\n",
            "[38,   400/  469] train loss: 0.022 train accuracy: 1.000\n",
            "[39,   100/  469] train loss: 0.018 train accuracy: 1.000\n",
            "[39,   200/  469] train loss: 0.015 train accuracy: 1.000\n",
            "[39,   300/  469] train loss: 0.023 train accuracy: 0.992\n",
            "[39,   400/  469] train loss: 0.028 train accuracy: 0.992\n",
            "[40,   100/  469] train loss: 0.016 train accuracy: 1.000\n",
            "[40,   200/  469] train loss: 0.018 train accuracy: 0.992\n",
            "[40,   300/  469] train loss: 0.010 train accuracy: 1.000\n",
            "[40,   400/  469] train loss: 0.018 train accuracy: 1.000\n",
            "[41,   100/  469] train loss: 0.017 train accuracy: 1.000\n",
            "[41,   200/  469] train loss: 0.018 train accuracy: 1.000\n",
            "[41,   300/  469] train loss: 0.011 train accuracy: 1.000\n",
            "[41,   400/  469] train loss: 0.017 train accuracy: 1.000\n",
            "[42,   100/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[42,   200/  469] train loss: 0.028 train accuracy: 1.000\n",
            "[42,   300/  469] train loss: 0.028 train accuracy: 1.000\n",
            "[42,   400/  469] train loss: 0.005 train accuracy: 1.000\n",
            "[43,   100/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[43,   200/  469] train loss: 0.009 train accuracy: 1.000\n",
            "[43,   300/  469] train loss: 0.022 train accuracy: 1.000\n",
            "[43,   400/  469] train loss: 0.021 train accuracy: 0.992\n",
            "[44,   100/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[44,   200/  469] train loss: 0.016 train accuracy: 1.000\n",
            "[44,   300/  469] train loss: 0.022 train accuracy: 0.992\n",
            "[44,   400/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[45,   100/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[45,   200/  469] train loss: 0.023 train accuracy: 0.992\n",
            "[45,   300/  469] train loss: 0.020 train accuracy: 1.000\n",
            "[45,   400/  469] train loss: 0.049 train accuracy: 0.992\n",
            "[46,   100/  469] train loss: 0.020 train accuracy: 1.000\n",
            "[46,   200/  469] train loss: 0.024 train accuracy: 1.000\n",
            "[46,   300/  469] train loss: 0.023 train accuracy: 1.000\n",
            "[46,   400/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[47,   100/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[47,   200/  469] train loss: 0.011 train accuracy: 1.000\n",
            "[47,   300/  469] train loss: 0.008 train accuracy: 1.000\n",
            "[47,   400/  469] train loss: 0.023 train accuracy: 0.992\n",
            "[48,   100/  469] train loss: 0.010 train accuracy: 1.000\n",
            "[48,   200/  469] train loss: 0.028 train accuracy: 1.000\n",
            "[48,   300/  469] train loss: 0.010 train accuracy: 1.000\n",
            "[48,   400/  469] train loss: 0.019 train accuracy: 0.992\n",
            "[49,   100/  469] train loss: 0.017 train accuracy: 1.000\n",
            "[49,   200/  469] train loss: 0.019 train accuracy: 1.000\n",
            "[49,   300/  469] train loss: 0.007 train accuracy: 1.000\n",
            "[49,   400/  469] train loss: 0.011 train accuracy: 1.000\n",
            "[50,   100/  469] train loss: 0.012 train accuracy: 1.000\n",
            "[50,   200/  469] train loss: 0.011 train accuracy: 1.000\n",
            "[50,   300/  469] train loss: 0.045 train accuracy: 0.992\n",
            "[50,   400/  469] train loss: 0.021 train accuracy: 0.992\n",
            "[51,   100/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[51,   200/  469] train loss: 0.016 train accuracy: 1.000\n",
            "[51,   300/  469] train loss: 0.021 train accuracy: 1.000\n",
            "[51,   400/  469] train loss: 0.019 train accuracy: 1.000\n",
            "[52,   100/  469] train loss: 0.010 train accuracy: 1.000\n",
            "[52,   200/  469] train loss: 0.016 train accuracy: 0.992\n",
            "[52,   300/  469] train loss: 0.015 train accuracy: 1.000\n",
            "[52,   400/  469] train loss: 0.035 train accuracy: 0.984\n",
            "[53,   100/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[53,   200/  469] train loss: 0.027 train accuracy: 0.992\n",
            "[53,   300/  469] train loss: 0.019 train accuracy: 0.992\n",
            "[53,   400/  469] train loss: 0.009 train accuracy: 1.000\n",
            "[54,   100/  469] train loss: 0.022 train accuracy: 1.000\n",
            "[54,   200/  469] train loss: 0.024 train accuracy: 0.992\n",
            "[54,   300/  469] train loss: 0.009 train accuracy: 1.000\n",
            "[54,   400/  469] train loss: 0.025 train accuracy: 0.992\n",
            "[55,   100/  469] train loss: 0.058 train accuracy: 0.984\n",
            "[55,   200/  469] train loss: 0.017 train accuracy: 1.000\n",
            "[55,   300/  469] train loss: 0.021 train accuracy: 1.000\n",
            "[55,   400/  469] train loss: 0.012 train accuracy: 1.000\n",
            "[56,   100/  469] train loss: 0.009 train accuracy: 1.000\n",
            "[56,   200/  469] train loss: 0.031 train accuracy: 0.992\n",
            "[56,   300/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[56,   400/  469] train loss: 0.018 train accuracy: 1.000\n",
            "[57,   100/  469] train loss: 0.006 train accuracy: 1.000\n",
            "[57,   200/  469] train loss: 0.013 train accuracy: 1.000\n",
            "[57,   300/  469] train loss: 0.006 train accuracy: 1.000\n",
            "[57,   400/  469] train loss: 0.019 train accuracy: 1.000\n",
            "[58,   100/  469] train loss: 0.014 train accuracy: 1.000\n",
            "[58,   200/  469] train loss: 0.036 train accuracy: 0.984\n",
            "[58,   300/  469] train loss: 0.023 train accuracy: 0.992\n",
            "[58,   400/  469] train loss: 0.020 train accuracy: 0.992\n",
            "[59,   100/  469] train loss: 0.016 train accuracy: 0.992\n",
            "[59,   200/  469] train loss: 0.017 train accuracy: 1.000\n",
            "[59,   300/  469] train loss: 0.018 train accuracy: 1.000\n",
            "[59,   400/  469] train loss: 0.020 train accuracy: 1.000\n",
            "[60,   100/  469] train loss: 0.038 train accuracy: 0.977\n",
            "[60,   200/  469] train loss: 0.006 train accuracy: 1.000\n",
            "[60,   300/  469] train loss: 0.015 train accuracy: 1.000\n",
            "[60,   400/  469] train loss: 0.019 train accuracy: 0.992\n"
          ]
        }
      ],
      "source": [
        "temperatures = [1]    # temperature for distillation loss\n",
        "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
        "# loss = alpha * st + (1 - alpha) * tt\n",
        "alphas = [0.0]\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "# No dropout used\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_no_distill = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    student_net = StudentNetwork()\n",
        "    student_net = student_net.to(fast_device)\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results_no_distill[hparam_tuple] = trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "                                                                    train_val_loader, None, \n",
        "                                                                    print_every=print_every, \n",
        "                                                                    fast_device=fast_device)\n",
        "    save_path = checkpoints_path_student + hparamToString(hparam) + '_no_distillation_final.tar'\n",
        "    torch.save({'results' : results_no_distill[hparam_tuple], \n",
        "                'model_state_dict' : student_net.state_dict(), \n",
        "                'epoch' : num_epochs}, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pmn_iXMbnU5"
      },
      "source": [
        "## Calculate student test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aGUpjI_bjTE",
        "outputId": "fc1d61b7-1cb0-40bb-c1c1-8f5ca67265b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "student test accuracy (w/o distillation):  0.9806\n"
          ]
        }
      ],
      "source": [
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "print('student test accuracy (w/o distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxb3fgdOE_U_"
      },
      "source": [
        "# View loaded weight FLOPS and parmater on Teacher and Student (Vanilla)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcONHdOqFDVg"
      },
      "outputs": [],
      "source": [
        "teacher_net = TeacherNetwork()\n",
        "teacher_net.load_state_dict(torch.load('checkpoints_teacher/dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05_final.tar', map_location=fast_device)['model_state_dict'])\n",
        "teacher_net = teacher_net.to(fast_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ5NKTMDIb0y"
      },
      "outputs": [],
      "source": [
        "data = train_dataset[1][0].to(fast_device)\n",
        "out = teacher_net.forward(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR2922MxGxX4",
        "outputId": "985a7437-eaa8-4cd7-d25b-413c9f3ec395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fc1        (1, 784)             (1, 1200)            torch.Size([1200, 784]) 940800     940800    \n",
            "fc2        (1, 1200)            (1, 1200)            torch.Size([1200, 1200]) 1440000    1440000   \n",
            "fc3        (1, 1200)            (1, 10)              torch.Size([10, 1200]) 12000      12000     \n"
          ]
        }
      ],
      "source": [
        "print_the_model_out(teacher_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKe5BbmgNOLJ"
      },
      "outputs": [],
      "source": [
        "student_net = StudentNetwork()\n",
        "student_net.load_state_dict(torch.load('checkpoints_student/T=1, alpha=0.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05_no_distillation_final.tar', map_location=fast_device)['model_state_dict'])\n",
        "student_net = student_net.to(fast_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OxgIc1pNZKy"
      },
      "outputs": [],
      "source": [
        "data = test_dataset[1][0].to(fast_device)\n",
        "out = student_net.forward(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXwOGjDLNigW",
        "outputId": "089116da-611e-4836-af9e-bd231296d196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fc1        (1, 784)             (1, 400)             torch.Size([400, 784]) 313600     313600    \n",
            "fc2        (1, 400)             (1, 10)              torch.Size([10, 400]) 4000       4000      \n"
          ]
        }
      ],
      "source": [
        "print_the_model_out(student_net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzFCzR3cb2qh"
      },
      "source": [
        "# Student Training with Distillation (Temperature = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7BeOVMr4bvS4"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60\n",
        "print_every = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XHJ7mW-jb5nH",
        "outputId": "4f4948a9-c4d5-4a1f-afed-4381501faf9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
            "[1,   100/  469] train loss: 4.576 train accuracy: 0.859\n",
            "[1,   200/  469] train loss: 4.671 train accuracy: 0.859\n",
            "[1,   300/  469] train loss: 3.365 train accuracy: 0.953\n",
            "[1,   400/  469] train loss: 3.962 train accuracy: 0.945\n",
            "[2,   100/  469] train loss: 3.606 train accuracy: 0.953\n",
            "[2,   200/  469] train loss: 3.654 train accuracy: 0.961\n",
            "[2,   300/  469] train loss: 3.580 train accuracy: 0.969\n",
            "[2,   400/  469] train loss: 3.577 train accuracy: 0.953\n",
            "[3,   100/  469] train loss: 3.372 train accuracy: 1.000\n",
            "[3,   200/  469] train loss: 3.675 train accuracy: 0.969\n",
            "[3,   300/  469] train loss: 3.607 train accuracy: 0.945\n",
            "[3,   400/  469] train loss: 3.646 train accuracy: 0.953\n",
            "[4,   100/  469] train loss: 3.477 train accuracy: 0.977\n",
            "[4,   200/  469] train loss: 3.378 train accuracy: 0.922\n",
            "[4,   300/  469] train loss: 3.405 train accuracy: 0.969\n",
            "[4,   400/  469] train loss: 3.882 train accuracy: 0.961\n",
            "[5,   100/  469] train loss: 3.437 train accuracy: 0.961\n",
            "[5,   200/  469] train loss: 3.337 train accuracy: 0.992\n",
            "[5,   300/  469] train loss: 3.538 train accuracy: 0.953\n",
            "[5,   400/  469] train loss: 3.378 train accuracy: 0.992\n",
            "[6,   100/  469] train loss: 3.698 train accuracy: 0.992\n",
            "[6,   200/  469] train loss: 3.411 train accuracy: 0.969\n",
            "[6,   300/  469] train loss: 3.475 train accuracy: 0.961\n",
            "[6,   400/  469] train loss: 3.276 train accuracy: 0.977\n",
            "[7,   100/  469] train loss: 2.982 train accuracy: 0.984\n",
            "[7,   200/  469] train loss: 2.986 train accuracy: 0.969\n",
            "[7,   300/  469] train loss: 3.132 train accuracy: 0.984\n",
            "[7,   400/  469] train loss: 3.472 train accuracy: 0.984\n",
            "[8,   100/  469] train loss: 3.332 train accuracy: 0.977\n",
            "[8,   200/  469] train loss: 3.292 train accuracy: 0.992\n",
            "[8,   300/  469] train loss: 3.298 train accuracy: 1.000\n",
            "[8,   400/  469] train loss: 2.884 train accuracy: 0.977\n",
            "[9,   100/  469] train loss: 3.230 train accuracy: 1.000\n",
            "[9,   200/  469] train loss: 3.384 train accuracy: 0.992\n",
            "[9,   300/  469] train loss: 3.528 train accuracy: 0.969\n",
            "[9,   400/  469] train loss: 3.143 train accuracy: 1.000\n",
            "[10,   100/  469] train loss: 3.119 train accuracy: 0.945\n",
            "[10,   200/  469] train loss: 3.379 train accuracy: 0.984\n",
            "[10,   300/  469] train loss: 3.384 train accuracy: 0.977\n",
            "[10,   400/  469] train loss: 3.312 train accuracy: 0.969\n",
            "[11,   100/  469] train loss: 3.310 train accuracy: 0.977\n",
            "[11,   200/  469] train loss: 3.243 train accuracy: 0.992\n",
            "[11,   300/  469] train loss: 3.760 train accuracy: 1.000\n",
            "[11,   400/  469] train loss: 3.213 train accuracy: 1.000\n",
            "[12,   100/  469] train loss: 3.193 train accuracy: 1.000\n",
            "[12,   200/  469] train loss: 3.067 train accuracy: 0.992\n",
            "[12,   300/  469] train loss: 3.302 train accuracy: 0.992\n",
            "[12,   400/  469] train loss: 3.509 train accuracy: 0.992\n",
            "[13,   100/  469] train loss: 3.282 train accuracy: 0.984\n",
            "[13,   200/  469] train loss: 3.281 train accuracy: 0.969\n",
            "[13,   300/  469] train loss: 3.588 train accuracy: 0.969\n",
            "[13,   400/  469] train loss: 2.938 train accuracy: 0.984\n",
            "[14,   100/  469] train loss: 3.264 train accuracy: 0.953\n",
            "[14,   200/  469] train loss: 3.214 train accuracy: 0.992\n",
            "[14,   300/  469] train loss: 3.178 train accuracy: 0.992\n",
            "[14,   400/  469] train loss: 3.124 train accuracy: 0.969\n",
            "[15,   100/  469] train loss: 3.018 train accuracy: 0.992\n",
            "[15,   200/  469] train loss: 3.344 train accuracy: 0.992\n",
            "[15,   300/  469] train loss: 3.293 train accuracy: 0.984\n",
            "[15,   400/  469] train loss: 3.077 train accuracy: 0.992\n",
            "[16,   100/  469] train loss: 2.844 train accuracy: 0.992\n",
            "[16,   200/  469] train loss: 3.420 train accuracy: 0.984\n",
            "[16,   300/  469] train loss: 3.204 train accuracy: 0.977\n",
            "[16,   400/  469] train loss: 3.099 train accuracy: 0.977\n",
            "[17,   100/  469] train loss: 3.476 train accuracy: 0.977\n",
            "[17,   200/  469] train loss: 3.380 train accuracy: 0.984\n",
            "[17,   300/  469] train loss: 3.107 train accuracy: 0.992\n",
            "[17,   400/  469] train loss: 3.217 train accuracy: 0.977\n",
            "[18,   100/  469] train loss: 3.293 train accuracy: 0.977\n",
            "[18,   200/  469] train loss: 3.162 train accuracy: 0.977\n",
            "[18,   300/  469] train loss: 3.315 train accuracy: 0.977\n",
            "[18,   400/  469] train loss: 3.187 train accuracy: 1.000\n",
            "[19,   100/  469] train loss: 3.220 train accuracy: 0.984\n",
            "[19,   200/  469] train loss: 3.187 train accuracy: 0.984\n",
            "[19,   300/  469] train loss: 3.177 train accuracy: 0.992\n",
            "[19,   400/  469] train loss: 3.042 train accuracy: 1.000\n",
            "[20,   100/  469] train loss: 3.217 train accuracy: 1.000\n",
            "[20,   200/  469] train loss: 3.162 train accuracy: 1.000\n",
            "[20,   300/  469] train loss: 3.530 train accuracy: 0.992\n",
            "[20,   400/  469] train loss: 3.042 train accuracy: 0.992\n",
            "[21,   100/  469] train loss: 3.259 train accuracy: 0.992\n",
            "[21,   200/  469] train loss: 3.399 train accuracy: 0.992\n",
            "[21,   300/  469] train loss: 3.181 train accuracy: 0.984\n",
            "[21,   400/  469] train loss: 3.018 train accuracy: 0.992\n",
            "[22,   100/  469] train loss: 3.413 train accuracy: 0.984\n",
            "[22,   200/  469] train loss: 3.033 train accuracy: 1.000\n",
            "[22,   300/  469] train loss: 3.245 train accuracy: 0.977\n",
            "[22,   400/  469] train loss: 3.196 train accuracy: 0.992\n",
            "[23,   100/  469] train loss: 3.205 train accuracy: 0.992\n",
            "[23,   200/  469] train loss: 3.191 train accuracy: 0.984\n",
            "[23,   300/  469] train loss: 3.294 train accuracy: 0.977\n",
            "[23,   400/  469] train loss: 3.460 train accuracy: 0.969\n",
            "[24,   100/  469] train loss: 3.173 train accuracy: 0.992\n",
            "[24,   200/  469] train loss: 2.715 train accuracy: 1.000\n",
            "[24,   300/  469] train loss: 3.282 train accuracy: 0.977\n",
            "[24,   400/  469] train loss: 3.119 train accuracy: 1.000\n",
            "[25,   100/  469] train loss: 3.289 train accuracy: 0.992\n",
            "[25,   200/  469] train loss: 3.153 train accuracy: 1.000\n",
            "[25,   300/  469] train loss: 3.084 train accuracy: 0.977\n",
            "[25,   400/  469] train loss: 2.959 train accuracy: 0.977\n",
            "[26,   100/  469] train loss: 3.313 train accuracy: 1.000\n",
            "[26,   200/  469] train loss: 3.512 train accuracy: 1.000\n",
            "[26,   300/  469] train loss: 2.900 train accuracy: 0.992\n",
            "[26,   400/  469] train loss: 3.193 train accuracy: 0.992\n",
            "[27,   100/  469] train loss: 3.092 train accuracy: 0.992\n",
            "[27,   200/  469] train loss: 3.117 train accuracy: 0.984\n",
            "[27,   300/  469] train loss: 3.369 train accuracy: 0.992\n",
            "[27,   400/  469] train loss: 3.441 train accuracy: 0.992\n",
            "[28,   100/  469] train loss: 3.218 train accuracy: 0.984\n",
            "[28,   200/  469] train loss: 3.035 train accuracy: 0.984\n",
            "[28,   300/  469] train loss: 3.099 train accuracy: 0.984\n",
            "[28,   400/  469] train loss: 3.409 train accuracy: 0.992\n",
            "[29,   100/  469] train loss: 3.012 train accuracy: 0.992\n",
            "[29,   200/  469] train loss: 3.117 train accuracy: 0.992\n",
            "[29,   300/  469] train loss: 3.291 train accuracy: 0.992\n",
            "[29,   400/  469] train loss: 3.111 train accuracy: 0.992\n",
            "[30,   100/  469] train loss: 3.300 train accuracy: 0.984\n",
            "[30,   200/  469] train loss: 3.208 train accuracy: 1.000\n",
            "[30,   300/  469] train loss: 3.163 train accuracy: 0.992\n",
            "[30,   400/  469] train loss: 3.343 train accuracy: 0.984\n",
            "[31,   100/  469] train loss: 3.093 train accuracy: 1.000\n",
            "[31,   200/  469] train loss: 2.989 train accuracy: 0.992\n",
            "[31,   300/  469] train loss: 3.430 train accuracy: 1.000\n",
            "[31,   400/  469] train loss: 3.359 train accuracy: 0.977\n",
            "[32,   100/  469] train loss: 3.208 train accuracy: 1.000\n",
            "[32,   200/  469] train loss: 2.922 train accuracy: 0.977\n",
            "[32,   300/  469] train loss: 2.780 train accuracy: 1.000\n",
            "[32,   400/  469] train loss: 3.036 train accuracy: 0.984\n",
            "[33,   100/  469] train loss: 3.402 train accuracy: 0.992\n",
            "[33,   200/  469] train loss: 3.511 train accuracy: 0.992\n",
            "[33,   300/  469] train loss: 3.120 train accuracy: 0.992\n",
            "[33,   400/  469] train loss: 3.150 train accuracy: 0.992\n",
            "[34,   100/  469] train loss: 2.841 train accuracy: 0.992\n",
            "[34,   200/  469] train loss: 3.503 train accuracy: 1.000\n",
            "[34,   300/  469] train loss: 3.377 train accuracy: 0.992\n",
            "[34,   400/  469] train loss: 3.619 train accuracy: 0.969\n",
            "[35,   100/  469] train loss: 3.103 train accuracy: 1.000\n",
            "[35,   200/  469] train loss: 3.243 train accuracy: 0.977\n",
            "[35,   300/  469] train loss: 3.212 train accuracy: 0.992\n",
            "[35,   400/  469] train loss: 3.306 train accuracy: 0.992\n",
            "[36,   100/  469] train loss: 2.907 train accuracy: 1.000\n",
            "[36,   200/  469] train loss: 3.180 train accuracy: 0.977\n",
            "[36,   300/  469] train loss: 3.192 train accuracy: 0.984\n",
            "[36,   400/  469] train loss: 3.325 train accuracy: 0.984\n",
            "[37,   100/  469] train loss: 3.288 train accuracy: 0.977\n",
            "[37,   200/  469] train loss: 3.406 train accuracy: 0.992\n",
            "[37,   300/  469] train loss: 3.659 train accuracy: 0.992\n",
            "[37,   400/  469] train loss: 2.862 train accuracy: 0.984\n",
            "[38,   100/  469] train loss: 2.866 train accuracy: 1.000\n",
            "[38,   200/  469] train loss: 3.158 train accuracy: 0.984\n",
            "[38,   300/  469] train loss: 3.172 train accuracy: 0.984\n",
            "[38,   400/  469] train loss: 3.193 train accuracy: 0.984\n",
            "[39,   100/  469] train loss: 3.018 train accuracy: 1.000\n",
            "[39,   200/  469] train loss: 2.990 train accuracy: 1.000\n",
            "[39,   300/  469] train loss: 3.565 train accuracy: 0.984\n",
            "[39,   400/  469] train loss: 3.223 train accuracy: 0.992\n",
            "[40,   100/  469] train loss: 3.473 train accuracy: 0.992\n",
            "[40,   200/  469] train loss: 3.391 train accuracy: 0.992\n",
            "[40,   300/  469] train loss: 3.094 train accuracy: 0.977\n",
            "[40,   400/  469] train loss: 3.238 train accuracy: 0.992\n",
            "[41,   100/  469] train loss: 3.046 train accuracy: 1.000\n",
            "[41,   200/  469] train loss: 3.192 train accuracy: 0.984\n",
            "[41,   300/  469] train loss: 3.331 train accuracy: 0.992\n",
            "[41,   400/  469] train loss: 3.182 train accuracy: 1.000\n",
            "[42,   100/  469] train loss: 3.063 train accuracy: 0.992\n",
            "[42,   200/  469] train loss: 3.362 train accuracy: 0.992\n",
            "[42,   300/  469] train loss: 3.419 train accuracy: 1.000\n",
            "[42,   400/  469] train loss: 3.375 train accuracy: 1.000\n",
            "[43,   100/  469] train loss: 3.074 train accuracy: 0.984\n",
            "[43,   200/  469] train loss: 3.195 train accuracy: 1.000\n",
            "[43,   300/  469] train loss: 3.265 train accuracy: 0.984\n",
            "[43,   400/  469] train loss: 3.369 train accuracy: 0.984\n",
            "[44,   100/  469] train loss: 3.197 train accuracy: 1.000\n",
            "[44,   200/  469] train loss: 2.952 train accuracy: 1.000\n",
            "[44,   300/  469] train loss: 3.106 train accuracy: 0.992\n",
            "[44,   400/  469] train loss: 3.225 train accuracy: 1.000\n",
            "[45,   100/  469] train loss: 3.093 train accuracy: 0.992\n",
            "[45,   200/  469] train loss: 3.070 train accuracy: 0.977\n",
            "[45,   300/  469] train loss: 3.209 train accuracy: 0.992\n",
            "[45,   400/  469] train loss: 3.264 train accuracy: 0.977\n",
            "[46,   100/  469] train loss: 2.782 train accuracy: 1.000\n",
            "[46,   200/  469] train loss: 3.151 train accuracy: 0.984\n",
            "[46,   300/  469] train loss: 2.806 train accuracy: 0.992\n",
            "[46,   400/  469] train loss: 2.806 train accuracy: 0.992\n",
            "[47,   100/  469] train loss: 3.100 train accuracy: 1.000\n",
            "[47,   200/  469] train loss: 3.247 train accuracy: 0.992\n",
            "[47,   300/  469] train loss: 3.175 train accuracy: 1.000\n",
            "[47,   400/  469] train loss: 3.125 train accuracy: 0.984\n",
            "[48,   100/  469] train loss: 3.268 train accuracy: 1.000\n",
            "[48,   200/  469] train loss: 3.180 train accuracy: 0.992\n",
            "[48,   300/  469] train loss: 3.615 train accuracy: 1.000\n",
            "[48,   400/  469] train loss: 3.437 train accuracy: 1.000\n",
            "[49,   100/  469] train loss: 3.203 train accuracy: 0.984\n",
            "[49,   200/  469] train loss: 3.575 train accuracy: 0.984\n",
            "[49,   300/  469] train loss: 3.183 train accuracy: 0.992\n",
            "[49,   400/  469] train loss: 3.244 train accuracy: 0.992\n",
            "[50,   100/  469] train loss: 2.993 train accuracy: 1.000\n",
            "[50,   200/  469] train loss: 3.202 train accuracy: 0.992\n",
            "[50,   300/  469] train loss: 3.376 train accuracy: 0.961\n",
            "[50,   400/  469] train loss: 3.172 train accuracy: 0.992\n",
            "[51,   100/  469] train loss: 3.087 train accuracy: 0.977\n",
            "[51,   200/  469] train loss: 3.039 train accuracy: 0.984\n",
            "[51,   300/  469] train loss: 3.216 train accuracy: 0.992\n",
            "[51,   400/  469] train loss: 3.069 train accuracy: 1.000\n",
            "[52,   100/  469] train loss: 3.259 train accuracy: 0.992\n",
            "[52,   200/  469] train loss: 3.313 train accuracy: 1.000\n",
            "[52,   300/  469] train loss: 3.128 train accuracy: 1.000\n",
            "[52,   400/  469] train loss: 2.991 train accuracy: 0.984\n",
            "[53,   100/  469] train loss: 3.148 train accuracy: 0.977\n",
            "[53,   200/  469] train loss: 2.663 train accuracy: 0.977\n",
            "[53,   300/  469] train loss: 3.080 train accuracy: 0.984\n",
            "[53,   400/  469] train loss: 3.317 train accuracy: 1.000\n",
            "[54,   100/  469] train loss: 3.225 train accuracy: 0.992\n",
            "[54,   200/  469] train loss: 3.669 train accuracy: 0.992\n",
            "[54,   300/  469] train loss: 2.965 train accuracy: 1.000\n",
            "[54,   400/  469] train loss: 3.037 train accuracy: 0.977\n",
            "[55,   100/  469] train loss: 3.233 train accuracy: 0.984\n",
            "[55,   200/  469] train loss: 3.111 train accuracy: 0.992\n",
            "[55,   300/  469] train loss: 3.108 train accuracy: 0.984\n",
            "[55,   400/  469] train loss: 3.032 train accuracy: 0.984\n",
            "[56,   100/  469] train loss: 3.314 train accuracy: 1.000\n",
            "[56,   200/  469] train loss: 3.280 train accuracy: 0.984\n",
            "[56,   300/  469] train loss: 3.419 train accuracy: 0.984\n",
            "[56,   400/  469] train loss: 2.918 train accuracy: 0.977\n",
            "[57,   100/  469] train loss: 3.111 train accuracy: 1.000\n",
            "[57,   200/  469] train loss: 3.085 train accuracy: 0.992\n",
            "[57,   300/  469] train loss: 3.154 train accuracy: 1.000\n",
            "[57,   400/  469] train loss: 3.230 train accuracy: 0.984\n",
            "[58,   100/  469] train loss: 2.971 train accuracy: 0.992\n",
            "[58,   200/  469] train loss: 3.211 train accuracy: 0.961\n",
            "[58,   300/  469] train loss: 3.097 train accuracy: 0.984\n",
            "[58,   400/  469] train loss: 3.121 train accuracy: 0.977\n",
            "[59,   100/  469] train loss: 3.044 train accuracy: 0.992\n",
            "[59,   200/  469] train loss: 3.098 train accuracy: 0.992\n",
            "[59,   300/  469] train loss: 3.480 train accuracy: 0.992\n",
            "[59,   400/  469] train loss: 3.032 train accuracy: 1.000\n",
            "[60,   100/  469] train loss: 3.352 train accuracy: 0.977\n",
            "[60,   200/  469] train loss: 3.022 train accuracy: 1.000\n",
            "[60,   300/  469] train loss: 3.238 train accuracy: 1.000\n",
            "[60,   400/  469] train loss: 3.545 train accuracy: 0.992\n"
          ]
        }
      ],
      "source": [
        "temperatures = [10]\n",
        "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
        "# loss = alpha * st + (1 - alpha) * tt\n",
        "alphas = [0.5]\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    student_net = StudentNetwork()\n",
        "    student_net = student_net.to(fast_device)\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "                                                                train_val_loader, None, \n",
        "                                                                print_every=print_every, \n",
        "                                                                fast_device=fast_device)\n",
        "    save_path = checkpoints_path_student + hparamToString(hparam) + '_distillation_final.tar'\n",
        "    torch.save({'results' : results_distill[hparam_tuple], \n",
        "                'model_state_dict' : student_net.state_dict(), \n",
        "                'epoch' : num_epochs}, save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuZYbsMYb-pO"
      },
      "source": [
        "## Calculate student test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PieUNKWxb7C5",
        "outputId": "65a0749e-20e3-46a3-fa80-bed6e1be588a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "student test accuracy (w distillation):  0.985\n"
          ]
        }
      ],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "print('student test accuracy (w distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ1fVVKFoFuT"
      },
      "source": [
        "# Student Training with Distillation (Temperature = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_Ak5rAfoKne"
      },
      "outputs": [],
      "source": [
        "temperatures = [20]\n",
        "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
        "# loss = alpha * st + (1 - alpha) * tt\n",
        "alphas = [0.5]\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    student_net = StudentNetwork()\n",
        "    student_net = student_net.to(fast_device)\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "                                                                train_val_loader, None, \n",
        "                                                                print_every=print_every, \n",
        "                                                                fast_device=fast_device)\n",
        "    save_path = checkpoints_path_student + hparamToString(hparam) + '_distillation_final.tar'\n",
        "    torch.save({'results' : results_distill[hparam_tuple], \n",
        "                'model_state_dict' : student_net.state_dict(), \n",
        "                'epoch' : num_epochs}, save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjgKyPVSoQe-"
      },
      "source": [
        "## Calculate student test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym4E-W5aoQe-"
      },
      "outputs": [],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "print('student test accuracy (w distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-VGPYsKoUJH"
      },
      "source": [
        "# Student Training with Distillation (Temperature = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bdZFAkioUJI"
      },
      "outputs": [],
      "source": [
        "temperatures = [5]\n",
        "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
        "# loss = alpha * st + (1 - alpha) * tt\n",
        "alphas = [0.5]\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    student_net = StudentNetwork()\n",
        "    student_net = student_net.to(fast_device)\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "                                                                train_val_loader, None, \n",
        "                                                                print_every=print_every, \n",
        "                                                                fast_device=fast_device)\n",
        "    save_path = checkpoints_path_student + hparamToString(hparam) + '_distillation_final.tar'\n",
        "    torch.save({'results' : results_distill[hparam_tuple], \n",
        "                'model_state_dict' : student_net.state_dict(), \n",
        "                'epoch' : num_epochs}, save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c1F3E5toUJI"
      },
      "source": [
        "## Calculate student test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnGMI3u5oUJI"
      },
      "outputs": [],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "print('student test accuracy (w distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxd-KnBMoqOR"
      },
      "source": [
        "# Student Training with Distillation (Temperature = 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NxTN44zoqOS"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60\n",
        "print_every = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22_R18aHoqOS"
      },
      "outputs": [],
      "source": [
        "temperatures = [25]\n",
        "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
        "# loss = alpha * st + (1 - alpha) * tt\n",
        "alphas = [0.5]\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    student_net = StudentNetwork()\n",
        "    student_net = student_net.to(fast_device)\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "                                                                train_val_loader, None, \n",
        "                                                                print_every=print_every, \n",
        "                                                                fast_device=fast_device)\n",
        "    save_path = checkpoints_path_student + hparamToString(hparam) + '_distillation_final.tar'\n",
        "    torch.save({'results' : results_distill[hparam_tuple], \n",
        "                'model_state_dict' : student_net.state_dict(), \n",
        "                'epoch' : num_epochs}, save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s-u0B-qoqOS"
      },
      "source": [
        "## Calculate student test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lS54kzRoqOS"
      },
      "outputs": [],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "print('student test accuracy (w distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbk1fSbaorhG"
      },
      "source": [
        "# Student Training with Distillation (Temperature = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1RJ5NUHborhH"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60\n",
        "print_every = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_ed2Mcz7orhH"
      },
      "outputs": [],
      "source": [
        "temperatures = [30]\n",
        "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
        "# loss = alpha * st + (1 - alpha) * tt\n",
        "alphas = [0.5]\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    student_net = StudentNetwork()\n",
        "    student_net = student_net.to(fast_device)\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "                                                                train_val_loader, None, \n",
        "                                                                print_every=print_every, \n",
        "                                                                fast_device=fast_device)\n",
        "    save_path = checkpoints_path_student + hparamToString(hparam) + '_distillation_final.tar'\n",
        "    torch.save({'results' : results_distill[hparam_tuple], \n",
        "                'model_state_dict' : student_net.state_dict(), \n",
        "                'epoch' : num_epochs}, save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsjHYSsUorhI"
      },
      "source": [
        "## Calculate student test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dT9709z8orhI"
      },
      "outputs": [],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "print('student test accuracy (w distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI_eelYH1HjZ"
      },
      "source": [
        "# Student Training with Distillation (Temperature = 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bi3dF9ot1HjZ"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60\n",
        "print_every = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "85eKlhvL1HjZ"
      },
      "outputs": [],
      "source": [
        "temperatures = [15]\n",
        "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
        "# loss = alpha * st + (1 - alpha) * tt\n",
        "alphas = [0.5]\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    student_net = StudentNetwork()\n",
        "    student_net = student_net.to(fast_device)\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "                                                                train_val_loader, None, \n",
        "                                                                print_every=print_every, \n",
        "                                                                fast_device=fast_device)\n",
        "    save_path = checkpoints_path_student + hparamToString(hparam) + '_distillation_final.tar'\n",
        "    torch.save({'results' : results_distill[hparam_tuple], \n",
        "                'model_state_dict' : student_net.state_dict(), \n",
        "                'epoch' : num_epochs}, save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEvcYcky1HjZ"
      },
      "source": [
        "## Calculate student test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MemChHNI1HjZ"
      },
      "outputs": [],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "print('student test accuracy (w distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNyeUhsSZfFJ"
      },
      "source": [
        "# Student training without digit one ground truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QiPYYP1rF7i"
      },
      "source": [
        "## Dataloader without digit one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYHWjg1srF7i"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Student trained without data augmentation\n",
        "transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.5], [0.5])\n",
        "                ]\n",
        "            )\n",
        "\n",
        "train_val_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=True, \n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=False, \n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "num_train = int(1.0 * len(train_val_dataset) * 95 / 100)\n",
        "num_val = len(train_val_dataset) - num_train\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
        "\n",
        "batch_size = 128\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAoIug51rF7i"
      },
      "outputs": [],
      "source": [
        "missing_digit = 1\n",
        "i = -1\n",
        "indices_list = []\n",
        "for img, index in train_val_dataset:\n",
        "    i += 1\n",
        "    if  index != missing_digit:\n",
        "        # print(i, \" index is not one\")\n",
        "        indices_list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHwvFczyrF7i"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "train_val_no_one_dataset = data_utils.Subset(train_val_dataset, indices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DHfUHhcNyOG"
      },
      "outputs": [],
      "source": [
        "missing_digit = 1\n",
        "i = -1\n",
        "indices_list = []\n",
        "for img, index in test_dataset:\n",
        "    i += 1\n",
        "    if  index != missing_digit:\n",
        "        # print(i, \" index is not one\")\n",
        "        indices_list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mltZX0kJrF7i"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "test_no_one_dataset = data_utils.Subset(test_dataset, indices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqEdLZEXrF7i"
      },
      "outputs": [],
      "source": [
        "train_val_no_one_loader = torch.utils.data.DataLoader(train_val_no_one_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_no_one_loader = torch.utils.data.DataLoader(test_no_one_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u05x-h9DZfFK"
      },
      "source": [
        "## Train student without distillation without one (T=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbkexVErZfFK"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60\n",
        "print_every = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIiU2KmWZfFK",
        "outputId": "d22f1410-5f94-4f45-caa1-50dcdb626340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=1, alpha=0.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
            "[1,   100/  417] train loss: 0.306 train accuracy: 0.922\n",
            "[1,   200/  417] train loss: 0.438 train accuracy: 0.859\n",
            "[1,   300/  417] train loss: 0.314 train accuracy: 0.930\n",
            "[1,   400/  417] train loss: 0.340 train accuracy: 0.906\n",
            "[2,   100/  417] train loss: 0.302 train accuracy: 0.898\n",
            "[2,   200/  417] train loss: 0.147 train accuracy: 0.969\n",
            "[2,   300/  417] train loss: 0.326 train accuracy: 0.906\n",
            "[2,   400/  417] train loss: 0.206 train accuracy: 0.945\n",
            "[3,   100/  417] train loss: 0.258 train accuracy: 0.930\n",
            "[3,   200/  417] train loss: 0.185 train accuracy: 0.961\n",
            "[3,   300/  417] train loss: 0.130 train accuracy: 0.969\n",
            "[3,   400/  417] train loss: 0.136 train accuracy: 0.953\n",
            "[4,   100/  417] train loss: 0.096 train accuracy: 0.969\n",
            "[4,   200/  417] train loss: 0.178 train accuracy: 0.953\n",
            "[4,   300/  417] train loss: 0.224 train accuracy: 0.922\n",
            "[4,   400/  417] train loss: 0.189 train accuracy: 0.945\n",
            "[5,   100/  417] train loss: 0.119 train accuracy: 0.977\n",
            "[5,   200/  417] train loss: 0.122 train accuracy: 0.969\n",
            "[5,   300/  417] train loss: 0.119 train accuracy: 0.961\n",
            "[5,   400/  417] train loss: 0.069 train accuracy: 0.992\n",
            "[6,   100/  417] train loss: 0.076 train accuracy: 0.977\n",
            "[6,   200/  417] train loss: 0.172 train accuracy: 0.961\n",
            "[6,   300/  417] train loss: 0.077 train accuracy: 0.984\n",
            "[6,   400/  417] train loss: 0.051 train accuracy: 0.992\n",
            "[7,   100/  417] train loss: 0.103 train accuracy: 0.977\n",
            "[7,   200/  417] train loss: 0.154 train accuracy: 0.969\n",
            "[7,   300/  417] train loss: 0.117 train accuracy: 0.961\n",
            "[7,   400/  417] train loss: 0.076 train accuracy: 0.969\n",
            "[8,   100/  417] train loss: 0.116 train accuracy: 0.969\n",
            "[8,   200/  417] train loss: 0.102 train accuracy: 0.953\n",
            "[8,   300/  417] train loss: 0.064 train accuracy: 0.984\n",
            "[8,   400/  417] train loss: 0.121 train accuracy: 0.969\n",
            "[9,   100/  417] train loss: 0.073 train accuracy: 0.984\n",
            "[9,   200/  417] train loss: 0.085 train accuracy: 0.969\n",
            "[9,   300/  417] train loss: 0.072 train accuracy: 0.969\n",
            "[9,   400/  417] train loss: 0.090 train accuracy: 0.977\n",
            "[10,   100/  417] train loss: 0.057 train accuracy: 0.984\n",
            "[10,   200/  417] train loss: 0.059 train accuracy: 0.992\n",
            "[10,   300/  417] train loss: 0.084 train accuracy: 0.969\n",
            "[10,   400/  417] train loss: 0.051 train accuracy: 0.992\n",
            "[11,   100/  417] train loss: 0.057 train accuracy: 0.977\n",
            "[11,   200/  417] train loss: 0.042 train accuracy: 0.992\n",
            "[11,   300/  417] train loss: 0.033 train accuracy: 0.992\n",
            "[11,   400/  417] train loss: 0.059 train accuracy: 0.984\n",
            "[12,   100/  417] train loss: 0.038 train accuracy: 0.984\n",
            "[12,   200/  417] train loss: 0.049 train accuracy: 0.984\n",
            "[12,   300/  417] train loss: 0.040 train accuracy: 1.000\n",
            "[12,   400/  417] train loss: 0.074 train accuracy: 0.977\n",
            "[13,   100/  417] train loss: 0.043 train accuracy: 0.984\n",
            "[13,   200/  417] train loss: 0.042 train accuracy: 0.984\n",
            "[13,   300/  417] train loss: 0.035 train accuracy: 0.992\n",
            "[13,   400/  417] train loss: 0.040 train accuracy: 0.977\n",
            "[14,   100/  417] train loss: 0.094 train accuracy: 0.977\n",
            "[14,   200/  417] train loss: 0.023 train accuracy: 1.000\n",
            "[14,   300/  417] train loss: 0.039 train accuracy: 0.992\n",
            "[14,   400/  417] train loss: 0.031 train accuracy: 0.984\n",
            "[15,   100/  417] train loss: 0.055 train accuracy: 0.992\n",
            "[15,   200/  417] train loss: 0.097 train accuracy: 0.977\n",
            "[15,   300/  417] train loss: 0.054 train accuracy: 0.984\n",
            "[15,   400/  417] train loss: 0.075 train accuracy: 0.977\n",
            "[16,   100/  417] train loss: 0.016 train accuracy: 1.000\n",
            "[16,   200/  417] train loss: 0.046 train accuracy: 0.984\n",
            "[16,   300/  417] train loss: 0.028 train accuracy: 1.000\n",
            "[16,   400/  417] train loss: 0.051 train accuracy: 0.992\n",
            "[17,   100/  417] train loss: 0.043 train accuracy: 0.992\n",
            "[17,   200/  417] train loss: 0.026 train accuracy: 1.000\n",
            "[17,   300/  417] train loss: 0.057 train accuracy: 0.984\n",
            "[17,   400/  417] train loss: 0.021 train accuracy: 1.000\n",
            "[18,   100/  417] train loss: 0.066 train accuracy: 0.977\n",
            "[18,   200/  417] train loss: 0.077 train accuracy: 0.977\n",
            "[18,   300/  417] train loss: 0.035 train accuracy: 0.992\n",
            "[18,   400/  417] train loss: 0.018 train accuracy: 0.992\n",
            "[19,   100/  417] train loss: 0.035 train accuracy: 0.984\n",
            "[19,   200/  417] train loss: 0.029 train accuracy: 1.000\n",
            "[19,   300/  417] train loss: 0.014 train accuracy: 1.000\n",
            "[19,   400/  417] train loss: 0.058 train accuracy: 0.977\n",
            "[20,   100/  417] train loss: 0.036 train accuracy: 1.000\n",
            "[20,   200/  417] train loss: 0.036 train accuracy: 0.992\n",
            "[20,   300/  417] train loss: 0.006 train accuracy: 1.000\n",
            "[20,   400/  417] train loss: 0.069 train accuracy: 0.984\n",
            "[21,   100/  417] train loss: 0.021 train accuracy: 1.000\n",
            "[21,   200/  417] train loss: 0.021 train accuracy: 1.000\n",
            "[21,   300/  417] train loss: 0.059 train accuracy: 0.977\n",
            "[21,   400/  417] train loss: 0.019 train accuracy: 1.000\n",
            "[22,   100/  417] train loss: 0.020 train accuracy: 1.000\n",
            "[22,   200/  417] train loss: 0.046 train accuracy: 0.992\n",
            "[22,   300/  417] train loss: 0.032 train accuracy: 0.992\n",
            "[22,   400/  417] train loss: 0.041 train accuracy: 0.984\n",
            "[23,   100/  417] train loss: 0.036 train accuracy: 0.984\n",
            "[23,   200/  417] train loss: 0.090 train accuracy: 0.977\n",
            "[23,   300/  417] train loss: 0.020 train accuracy: 1.000\n",
            "[23,   400/  417] train loss: 0.026 train accuracy: 1.000\n",
            "[24,   100/  417] train loss: 0.009 train accuracy: 1.000\n",
            "[24,   200/  417] train loss: 0.007 train accuracy: 1.000\n",
            "[24,   300/  417] train loss: 0.016 train accuracy: 1.000\n",
            "[24,   400/  417] train loss: 0.041 train accuracy: 0.992\n",
            "[25,   100/  417] train loss: 0.021 train accuracy: 1.000\n",
            "[25,   200/  417] train loss: 0.023 train accuracy: 1.000\n",
            "[25,   300/  417] train loss: 0.027 train accuracy: 0.992\n",
            "[25,   400/  417] train loss: 0.023 train accuracy: 1.000\n",
            "[26,   100/  417] train loss: 0.025 train accuracy: 1.000\n",
            "[26,   200/  417] train loss: 0.026 train accuracy: 1.000\n",
            "[26,   300/  417] train loss: 0.027 train accuracy: 1.000\n",
            "[26,   400/  417] train loss: 0.055 train accuracy: 0.984\n",
            "[27,   100/  417] train loss: 0.013 train accuracy: 1.000\n",
            "[27,   200/  417] train loss: 0.010 train accuracy: 1.000\n",
            "[27,   300/  417] train loss: 0.035 train accuracy: 0.992\n",
            "[27,   400/  417] train loss: 0.082 train accuracy: 0.961\n",
            "[28,   100/  417] train loss: 0.012 train accuracy: 1.000\n",
            "[28,   200/  417] train loss: 0.020 train accuracy: 1.000\n",
            "[28,   300/  417] train loss: 0.036 train accuracy: 0.984\n",
            "[28,   400/  417] train loss: 0.029 train accuracy: 0.992\n",
            "[29,   100/  417] train loss: 0.016 train accuracy: 1.000\n",
            "[29,   200/  417] train loss: 0.022 train accuracy: 1.000\n",
            "[29,   300/  417] train loss: 0.020 train accuracy: 1.000\n",
            "[29,   400/  417] train loss: 0.018 train accuracy: 1.000\n",
            "[30,   100/  417] train loss: 0.075 train accuracy: 0.984\n",
            "[30,   200/  417] train loss: 0.022 train accuracy: 0.984\n",
            "[30,   300/  417] train loss: 0.023 train accuracy: 0.992\n",
            "[30,   400/  417] train loss: 0.008 train accuracy: 1.000\n",
            "[31,   100/  417] train loss: 0.021 train accuracy: 1.000\n",
            "[31,   200/  417] train loss: 0.014 train accuracy: 1.000\n",
            "[31,   300/  417] train loss: 0.015 train accuracy: 1.000\n",
            "[31,   400/  417] train loss: 0.052 train accuracy: 0.992\n",
            "[32,   100/  417] train loss: 0.021 train accuracy: 1.000\n",
            "[32,   200/  417] train loss: 0.029 train accuracy: 0.984\n",
            "[32,   300/  417] train loss: 0.011 train accuracy: 1.000\n",
            "[32,   400/  417] train loss: 0.012 train accuracy: 1.000\n",
            "[33,   100/  417] train loss: 0.028 train accuracy: 0.992\n",
            "[33,   200/  417] train loss: 0.029 train accuracy: 0.992\n",
            "[33,   300/  417] train loss: 0.022 train accuracy: 1.000\n",
            "[33,   400/  417] train loss: 0.030 train accuracy: 1.000\n",
            "[34,   100/  417] train loss: 0.020 train accuracy: 0.992\n",
            "[34,   200/  417] train loss: 0.022 train accuracy: 1.000\n",
            "[34,   300/  417] train loss: 0.030 train accuracy: 0.992\n",
            "[34,   400/  417] train loss: 0.023 train accuracy: 0.992\n",
            "[35,   100/  417] train loss: 0.026 train accuracy: 1.000\n",
            "[35,   200/  417] train loss: 0.016 train accuracy: 1.000\n",
            "[35,   300/  417] train loss: 0.021 train accuracy: 1.000\n",
            "[35,   400/  417] train loss: 0.036 train accuracy: 0.992\n",
            "[36,   100/  417] train loss: 0.052 train accuracy: 0.984\n",
            "[36,   200/  417] train loss: 0.014 train accuracy: 1.000\n",
            "[36,   300/  417] train loss: 0.040 train accuracy: 0.992\n",
            "[36,   400/  417] train loss: 0.016 train accuracy: 0.992\n",
            "[37,   100/  417] train loss: 0.021 train accuracy: 0.984\n",
            "[37,   200/  417] train loss: 0.017 train accuracy: 1.000\n",
            "[37,   300/  417] train loss: 0.039 train accuracy: 0.992\n",
            "[37,   400/  417] train loss: 0.052 train accuracy: 0.992\n",
            "[38,   100/  417] train loss: 0.031 train accuracy: 0.992\n",
            "[38,   200/  417] train loss: 0.033 train accuracy: 0.992\n",
            "[38,   300/  417] train loss: 0.030 train accuracy: 0.992\n",
            "[38,   400/  417] train loss: 0.034 train accuracy: 0.984\n",
            "[39,   100/  417] train loss: 0.017 train accuracy: 1.000\n",
            "[39,   200/  417] train loss: 0.013 train accuracy: 1.000\n",
            "[39,   300/  417] train loss: 0.020 train accuracy: 1.000\n",
            "[39,   400/  417] train loss: 0.024 train accuracy: 0.992\n",
            "[40,   100/  417] train loss: 0.038 train accuracy: 0.992\n",
            "[40,   200/  417] train loss: 0.022 train accuracy: 1.000\n",
            "[40,   300/  417] train loss: 0.020 train accuracy: 0.992\n",
            "[40,   400/  417] train loss: 0.012 train accuracy: 1.000\n",
            "[41,   100/  417] train loss: 0.007 train accuracy: 1.000\n",
            "[41,   200/  417] train loss: 0.018 train accuracy: 1.000\n",
            "[41,   300/  417] train loss: 0.020 train accuracy: 1.000\n",
            "[41,   400/  417] train loss: 0.020 train accuracy: 0.992\n",
            "[42,   100/  417] train loss: 0.027 train accuracy: 0.992\n",
            "[42,   200/  417] train loss: 0.016 train accuracy: 1.000\n",
            "[42,   300/  417] train loss: 0.012 train accuracy: 1.000\n",
            "[42,   400/  417] train loss: 0.016 train accuracy: 1.000\n",
            "[43,   100/  417] train loss: 0.010 train accuracy: 1.000\n",
            "[43,   200/  417] train loss: 0.011 train accuracy: 1.000\n",
            "[43,   300/  417] train loss: 0.017 train accuracy: 1.000\n",
            "[43,   400/  417] train loss: 0.015 train accuracy: 1.000\n",
            "[44,   100/  417] train loss: 0.012 train accuracy: 1.000\n",
            "[44,   200/  417] train loss: 0.006 train accuracy: 1.000\n",
            "[44,   300/  417] train loss: 0.029 train accuracy: 0.992\n",
            "[44,   400/  417] train loss: 0.022 train accuracy: 0.992\n",
            "[45,   100/  417] train loss: 0.034 train accuracy: 0.984\n",
            "[45,   200/  417] train loss: 0.012 train accuracy: 1.000\n",
            "[45,   300/  417] train loss: 0.011 train accuracy: 1.000\n",
            "[45,   400/  417] train loss: 0.019 train accuracy: 1.000\n",
            "[46,   100/  417] train loss: 0.045 train accuracy: 0.992\n",
            "[46,   200/  417] train loss: 0.025 train accuracy: 0.992\n",
            "[46,   300/  417] train loss: 0.019 train accuracy: 0.992\n",
            "[46,   400/  417] train loss: 0.028 train accuracy: 1.000\n",
            "[47,   100/  417] train loss: 0.027 train accuracy: 0.992\n",
            "[47,   200/  417] train loss: 0.011 train accuracy: 1.000\n",
            "[47,   300/  417] train loss: 0.016 train accuracy: 1.000\n",
            "[47,   400/  417] train loss: 0.016 train accuracy: 1.000\n",
            "[48,   100/  417] train loss: 0.013 train accuracy: 1.000\n",
            "[48,   200/  417] train loss: 0.011 train accuracy: 1.000\n",
            "[48,   300/  417] train loss: 0.015 train accuracy: 1.000\n",
            "[48,   400/  417] train loss: 0.010 train accuracy: 1.000\n",
            "[49,   100/  417] train loss: 0.020 train accuracy: 1.000\n",
            "[49,   200/  417] train loss: 0.032 train accuracy: 0.984\n",
            "[49,   300/  417] train loss: 0.035 train accuracy: 0.992\n",
            "[49,   400/  417] train loss: 0.016 train accuracy: 1.000\n",
            "[50,   100/  417] train loss: 0.005 train accuracy: 1.000\n",
            "[50,   200/  417] train loss: 0.016 train accuracy: 1.000\n",
            "[50,   300/  417] train loss: 0.012 train accuracy: 1.000\n",
            "[50,   400/  417] train loss: 0.020 train accuracy: 1.000\n",
            "[51,   100/  417] train loss: 0.017 train accuracy: 1.000\n",
            "[51,   200/  417] train loss: 0.015 train accuracy: 1.000\n",
            "[51,   300/  417] train loss: 0.016 train accuracy: 0.992\n",
            "[51,   400/  417] train loss: 0.016 train accuracy: 1.000\n",
            "[52,   100/  417] train loss: 0.018 train accuracy: 1.000\n",
            "[52,   200/  417] train loss: 0.016 train accuracy: 1.000\n",
            "[52,   300/  417] train loss: 0.018 train accuracy: 1.000\n",
            "[52,   400/  417] train loss: 0.008 train accuracy: 1.000\n",
            "[53,   100/  417] train loss: 0.014 train accuracy: 1.000\n",
            "[53,   200/  417] train loss: 0.033 train accuracy: 1.000\n",
            "[53,   300/  417] train loss: 0.013 train accuracy: 1.000\n",
            "[53,   400/  417] train loss: 0.017 train accuracy: 1.000\n",
            "[54,   100/  417] train loss: 0.028 train accuracy: 1.000\n",
            "[54,   200/  417] train loss: 0.021 train accuracy: 1.000\n",
            "[54,   300/  417] train loss: 0.014 train accuracy: 0.992\n",
            "[54,   400/  417] train loss: 0.014 train accuracy: 1.000\n",
            "[55,   100/  417] train loss: 0.032 train accuracy: 0.984\n",
            "[55,   200/  417] train loss: 0.019 train accuracy: 1.000\n",
            "[55,   300/  417] train loss: 0.018 train accuracy: 0.992\n",
            "[55,   400/  417] train loss: 0.018 train accuracy: 1.000\n",
            "[56,   100/  417] train loss: 0.022 train accuracy: 1.000\n",
            "[56,   200/  417] train loss: 0.007 train accuracy: 1.000\n",
            "[56,   300/  417] train loss: 0.012 train accuracy: 1.000\n",
            "[56,   400/  417] train loss: 0.022 train accuracy: 0.992\n",
            "[57,   100/  417] train loss: 0.015 train accuracy: 1.000\n",
            "[57,   200/  417] train loss: 0.009 train accuracy: 1.000\n",
            "[57,   300/  417] train loss: 0.015 train accuracy: 1.000\n",
            "[57,   400/  417] train loss: 0.040 train accuracy: 0.992\n",
            "[58,   100/  417] train loss: 0.018 train accuracy: 0.992\n",
            "[58,   200/  417] train loss: 0.026 train accuracy: 0.992\n",
            "[58,   300/  417] train loss: 0.015 train accuracy: 0.992\n",
            "[58,   400/  417] train loss: 0.022 train accuracy: 1.000\n",
            "[59,   100/  417] train loss: 0.032 train accuracy: 0.992\n",
            "[59,   200/  417] train loss: 0.024 train accuracy: 0.992\n",
            "[59,   300/  417] train loss: 0.013 train accuracy: 1.000\n",
            "[59,   400/  417] train loss: 0.008 train accuracy: 1.000\n",
            "[60,   100/  417] train loss: 0.019 train accuracy: 1.000\n",
            "[60,   200/  417] train loss: 0.018 train accuracy: 1.000\n",
            "[60,   300/  417] train loss: 0.020 train accuracy: 1.000\n",
            "[60,   400/  417] train loss: 0.034 train accuracy: 0.992\n"
          ]
        }
      ],
      "source": [
        "temperatures = [1]    # temperature for distillation loss\n",
        "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
        "# loss = alpha * st + (1 - alpha) * tt\n",
        "alphas = [0.0]\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "# No dropout used\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    student_net = StudentNetwork()\n",
        "    student_net = student_net.to(fast_device)\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "                                                                train_val_no_one_loader, None, \n",
        "                                                                print_every=print_every, \n",
        "                                                                fast_device=fast_device)\n",
        "    save_path = checkpoints_path_student + hparamToString(hparam) + '_no_one_no_distillation_final.tar'\n",
        "    torch.save({'results' : results_distill[hparam_tuple], \n",
        "                'model_state_dict' : student_net.state_dict(), \n",
        "                'epoch' : num_epochs}, save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0PC43oe61LW"
      },
      "source": [
        "## DataLoader with only one in it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4FQsjve65eo"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Student trained without data augmentation\n",
        "transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.5], [0.5])\n",
        "                ]\n",
        "            )\n",
        "\n",
        "train_val_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=True, \n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=False, \n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "num_train = int(1.0 * len(train_val_dataset) * 95 / 100)\n",
        "num_val = len(train_val_dataset) - num_train\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
        "\n",
        "batch_size = 128\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFq7HrW-65eo"
      },
      "outputs": [],
      "source": [
        "missing_digit = 1\n",
        "i = -1\n",
        "indices_list = []\n",
        "for img, index in train_val_dataset:\n",
        "    i += 1\n",
        "    if  index == missing_digit:\n",
        "        # print(i, \" index is not one\")\n",
        "        indices_list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEKzfSxe65eo"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "train_val_only_one_dataset = data_utils.Subset(train_val_dataset, indices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKCtSlBQN4uR"
      },
      "outputs": [],
      "source": [
        "missing_digit = 1\n",
        "i = -1\n",
        "indices_list = []\n",
        "for img, index in test_dataset:\n",
        "    i += 1\n",
        "    if  index == missing_digit:\n",
        "        # print(i, \" index is not one\")\n",
        "        indices_list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWIEHlLt65eo"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "test_only_one_dataset = data_utils.Subset(test_dataset, indices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jz9idrrN65eo"
      },
      "outputs": [],
      "source": [
        "train_val_only_one_loader = torch.utils.data.DataLoader(train_val_only_one_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_only_one_loader = torch.utils.data.DataLoader(test_only_one_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETjFb1HqZfFK"
      },
      "source": [
        "## Calculate student test accuracy on one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE6lLlxfZfFL",
        "outputId": "a068d86f-4912-459d-b4c4-6df0581bf4fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "student test accuracy (w/o distillation) on one digit:  0.0\n"
          ]
        }
      ],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_only_one_loader, fast_device)\n",
        "print('student test accuracy (w/o distillation) on one digit: ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr9Gxm64ZfFL"
      },
      "source": [
        "## Calculate student test accuracy without one in it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QgBBcgRZfFL",
        "outputId": "c314c925-f1bf-46a9-b01e-8db7f8133208"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "student test accuracy (w/o distillation):  0.9803722504230118\n"
          ]
        }
      ],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_no_one_loader, fast_device)\n",
        "print('student test accuracy (w/o distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8pewkUB1cDR"
      },
      "source": [
        "# Vanilla Distillation with one digit missing (Digit One)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECBhv19fP7-F"
      },
      "source": [
        "## Dataloader without digit one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edTuA4R_1gX9"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Student trained without data augmentation\n",
        "transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.5], [0.5])\n",
        "                ]\n",
        "            )\n",
        "\n",
        "train_val_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=True, \n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=False, \n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "num_train = int(1.0 * len(train_val_dataset) * 95 / 100)\n",
        "num_val = len(train_val_dataset) - num_train\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
        "\n",
        "batch_size = 128\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVKwGFplQnmq"
      },
      "outputs": [],
      "source": [
        "i = -1\n",
        "indices_list = []\n",
        "for img, index in train_val_dataset:\n",
        "    i += 1\n",
        "    if  index != 1:\n",
        "        # print(i, \" index is not one\")\n",
        "        indices_list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvm5vyAJSl3T"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "train_val_no_one_dataset = data_utils.Subset(train_val_dataset, indices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl78ChUtVYL-"
      },
      "outputs": [],
      "source": [
        "i = -1\n",
        "indices_list = []\n",
        "for img, index in test_dataset:\n",
        "    i += 1\n",
        "    if  index != 1:\n",
        "        # print(i, \" index is not one\")\n",
        "        indices_list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JczmUwrvVbv2"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "test_no_one_dataset = data_utils.Subset(test_dataset, indices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKhibNlhU_fs"
      },
      "outputs": [],
      "source": [
        "train_val_no_one_loader = torch.utils.data.DataLoader(train_val_no_one_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_no_one_loader = torch.utils.data.DataLoader(test_no_one_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gC0cVwPVpda"
      },
      "source": [
        "## Train student without digit one with distillation (T=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yjVXBDXV0ET"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60\n",
        "print_every = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtJPxcB8Vw4q",
        "outputId": "335e2ecc-9659-4d7d-945f-360e1c196f99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
            "[1,   100/  417] train loss: 4.465 train accuracy: 0.914\n",
            "[1,   200/  417] train loss: 4.336 train accuracy: 0.891\n",
            "[1,   300/  417] train loss: 3.743 train accuracy: 0.953\n",
            "[1,   400/  417] train loss: 4.042 train accuracy: 0.906\n",
            "[2,   100/  417] train loss: 3.512 train accuracy: 0.914\n",
            "[2,   200/  417] train loss: 3.846 train accuracy: 0.977\n",
            "[2,   300/  417] train loss: 3.553 train accuracy: 0.922\n",
            "[2,   400/  417] train loss: 3.441 train accuracy: 0.953\n",
            "[3,   100/  417] train loss: 3.568 train accuracy: 0.938\n",
            "[3,   200/  417] train loss: 3.365 train accuracy: 0.938\n",
            "[3,   300/  417] train loss: 3.516 train accuracy: 0.977\n",
            "[3,   400/  417] train loss: 3.395 train accuracy: 0.977\n",
            "[4,   100/  417] train loss: 3.748 train accuracy: 0.953\n",
            "[4,   200/  417] train loss: 3.125 train accuracy: 0.961\n",
            "[4,   300/  417] train loss: 3.170 train accuracy: 0.945\n",
            "[4,   400/  417] train loss: 3.250 train accuracy: 0.953\n",
            "[5,   100/  417] train loss: 3.284 train accuracy: 0.969\n",
            "[5,   200/  417] train loss: 3.654 train accuracy: 0.984\n",
            "[5,   300/  417] train loss: 3.463 train accuracy: 0.984\n",
            "[5,   400/  417] train loss: 3.237 train accuracy: 0.992\n",
            "[6,   100/  417] train loss: 3.340 train accuracy: 0.969\n",
            "[6,   200/  417] train loss: 3.760 train accuracy: 0.953\n",
            "[6,   300/  417] train loss: 3.203 train accuracy: 0.984\n",
            "[6,   400/  417] train loss: 3.427 train accuracy: 0.977\n",
            "[7,   100/  417] train loss: 3.265 train accuracy: 0.961\n",
            "[7,   200/  417] train loss: 3.241 train accuracy: 0.969\n",
            "[7,   300/  417] train loss: 3.438 train accuracy: 0.969\n",
            "[7,   400/  417] train loss: 3.608 train accuracy: 0.977\n",
            "[8,   100/  417] train loss: 3.650 train accuracy: 0.969\n",
            "[8,   200/  417] train loss: 3.386 train accuracy: 0.977\n",
            "[8,   300/  417] train loss: 3.075 train accuracy: 0.984\n",
            "[8,   400/  417] train loss: 3.036 train accuracy: 0.969\n",
            "[9,   100/  417] train loss: 3.073 train accuracy: 0.992\n",
            "[9,   200/  417] train loss: 3.522 train accuracy: 0.969\n",
            "[9,   300/  417] train loss: 3.368 train accuracy: 0.984\n",
            "[9,   400/  417] train loss: 3.145 train accuracy: 0.984\n",
            "[10,   100/  417] train loss: 3.209 train accuracy: 0.984\n",
            "[10,   200/  417] train loss: 3.120 train accuracy: 0.992\n",
            "[10,   300/  417] train loss: 3.074 train accuracy: 0.969\n",
            "[10,   400/  417] train loss: 3.043 train accuracy: 0.992\n",
            "[11,   100/  417] train loss: 3.321 train accuracy: 0.977\n",
            "[11,   200/  417] train loss: 3.168 train accuracy: 1.000\n",
            "[11,   300/  417] train loss: 3.493 train accuracy: 0.992\n",
            "[11,   400/  417] train loss: 3.103 train accuracy: 0.969\n",
            "[12,   100/  417] train loss: 3.252 train accuracy: 0.992\n",
            "[12,   200/  417] train loss: 3.461 train accuracy: 0.992\n",
            "[12,   300/  417] train loss: 3.504 train accuracy: 1.000\n",
            "[12,   400/  417] train loss: 3.651 train accuracy: 0.969\n",
            "[13,   100/  417] train loss: 3.404 train accuracy: 0.992\n",
            "[13,   200/  417] train loss: 3.119 train accuracy: 0.977\n",
            "[13,   300/  417] train loss: 3.085 train accuracy: 0.969\n",
            "[13,   400/  417] train loss: 3.284 train accuracy: 0.969\n",
            "[14,   100/  417] train loss: 2.981 train accuracy: 0.961\n",
            "[14,   200/  417] train loss: 3.174 train accuracy: 0.984\n",
            "[14,   300/  417] train loss: 3.288 train accuracy: 0.984\n",
            "[14,   400/  417] train loss: 3.453 train accuracy: 0.992\n",
            "[15,   100/  417] train loss: 3.886 train accuracy: 0.977\n",
            "[15,   200/  417] train loss: 3.089 train accuracy: 0.969\n",
            "[15,   300/  417] train loss: 3.564 train accuracy: 0.992\n",
            "[15,   400/  417] train loss: 3.010 train accuracy: 0.977\n",
            "[16,   100/  417] train loss: 3.464 train accuracy: 0.992\n",
            "[16,   200/  417] train loss: 3.154 train accuracy: 0.992\n",
            "[16,   300/  417] train loss: 3.335 train accuracy: 0.992\n",
            "[16,   400/  417] train loss: 3.365 train accuracy: 0.984\n",
            "[17,   100/  417] train loss: 3.187 train accuracy: 0.977\n",
            "[17,   200/  417] train loss: 3.037 train accuracy: 0.992\n",
            "[17,   300/  417] train loss: 2.921 train accuracy: 0.961\n",
            "[17,   400/  417] train loss: 3.308 train accuracy: 0.992\n",
            "[18,   100/  417] train loss: 3.183 train accuracy: 0.977\n",
            "[18,   200/  417] train loss: 3.038 train accuracy: 0.984\n",
            "[18,   300/  417] train loss: 3.095 train accuracy: 0.992\n",
            "[18,   400/  417] train loss: 3.093 train accuracy: 1.000\n",
            "[19,   100/  417] train loss: 3.073 train accuracy: 0.992\n",
            "[19,   200/  417] train loss: 3.172 train accuracy: 0.961\n",
            "[19,   300/  417] train loss: 3.325 train accuracy: 0.992\n",
            "[19,   400/  417] train loss: 3.487 train accuracy: 0.984\n",
            "[20,   100/  417] train loss: 3.271 train accuracy: 0.992\n",
            "[20,   200/  417] train loss: 3.257 train accuracy: 0.992\n",
            "[20,   300/  417] train loss: 3.345 train accuracy: 1.000\n",
            "[20,   400/  417] train loss: 3.051 train accuracy: 0.961\n",
            "[21,   100/  417] train loss: 2.901 train accuracy: 0.992\n",
            "[21,   200/  417] train loss: 2.821 train accuracy: 0.984\n",
            "[21,   300/  417] train loss: 3.182 train accuracy: 0.977\n",
            "[21,   400/  417] train loss: 3.064 train accuracy: 1.000\n",
            "[22,   100/  417] train loss: 3.126 train accuracy: 1.000\n",
            "[22,   200/  417] train loss: 3.138 train accuracy: 0.977\n",
            "[22,   300/  417] train loss: 2.882 train accuracy: 0.984\n",
            "[22,   400/  417] train loss: 3.266 train accuracy: 0.977\n",
            "[23,   100/  417] train loss: 2.927 train accuracy: 0.992\n",
            "[23,   200/  417] train loss: 3.160 train accuracy: 0.953\n",
            "[23,   300/  417] train loss: 3.365 train accuracy: 0.992\n",
            "[23,   400/  417] train loss: 3.338 train accuracy: 1.000\n",
            "[24,   100/  417] train loss: 3.037 train accuracy: 1.000\n",
            "[24,   200/  417] train loss: 2.872 train accuracy: 1.000\n",
            "[24,   300/  417] train loss: 3.329 train accuracy: 0.977\n",
            "[24,   400/  417] train loss: 3.065 train accuracy: 1.000\n",
            "[25,   100/  417] train loss: 3.548 train accuracy: 0.984\n",
            "[25,   200/  417] train loss: 2.988 train accuracy: 0.992\n",
            "[25,   300/  417] train loss: 3.040 train accuracy: 1.000\n",
            "[25,   400/  417] train loss: 3.219 train accuracy: 0.992\n",
            "[26,   100/  417] train loss: 3.147 train accuracy: 0.992\n",
            "[26,   200/  417] train loss: 2.951 train accuracy: 0.992\n",
            "[26,   300/  417] train loss: 3.304 train accuracy: 0.969\n",
            "[26,   400/  417] train loss: 2.870 train accuracy: 0.977\n",
            "[27,   100/  417] train loss: 3.053 train accuracy: 0.992\n",
            "[27,   200/  417] train loss: 3.122 train accuracy: 1.000\n",
            "[27,   300/  417] train loss: 3.141 train accuracy: 0.977\n",
            "[27,   400/  417] train loss: 3.134 train accuracy: 0.938\n",
            "[28,   100/  417] train loss: 3.119 train accuracy: 0.992\n",
            "[28,   200/  417] train loss: 3.084 train accuracy: 0.992\n",
            "[28,   300/  417] train loss: 2.600 train accuracy: 0.969\n",
            "[28,   400/  417] train loss: 3.155 train accuracy: 0.969\n",
            "[29,   100/  417] train loss: 3.077 train accuracy: 0.992\n",
            "[29,   200/  417] train loss: 3.112 train accuracy: 0.992\n",
            "[29,   300/  417] train loss: 2.769 train accuracy: 0.984\n",
            "[29,   400/  417] train loss: 3.408 train accuracy: 0.992\n",
            "[30,   100/  417] train loss: 3.542 train accuracy: 0.984\n",
            "[30,   200/  417] train loss: 3.288 train accuracy: 0.992\n",
            "[30,   300/  417] train loss: 3.152 train accuracy: 0.984\n",
            "[30,   400/  417] train loss: 3.483 train accuracy: 0.992\n",
            "[31,   100/  417] train loss: 3.108 train accuracy: 0.992\n",
            "[31,   200/  417] train loss: 3.403 train accuracy: 0.992\n",
            "[31,   300/  417] train loss: 3.320 train accuracy: 1.000\n",
            "[31,   400/  417] train loss: 3.368 train accuracy: 0.977\n",
            "[32,   100/  417] train loss: 2.937 train accuracy: 0.992\n",
            "[32,   200/  417] train loss: 2.868 train accuracy: 0.969\n",
            "[32,   300/  417] train loss: 3.126 train accuracy: 1.000\n",
            "[32,   400/  417] train loss: 3.034 train accuracy: 0.992\n",
            "[33,   100/  417] train loss: 3.276 train accuracy: 0.992\n",
            "[33,   200/  417] train loss: 3.561 train accuracy: 0.984\n",
            "[33,   300/  417] train loss: 3.039 train accuracy: 0.992\n",
            "[33,   400/  417] train loss: 3.456 train accuracy: 0.992\n",
            "[34,   100/  417] train loss: 3.172 train accuracy: 0.992\n",
            "[34,   200/  417] train loss: 3.290 train accuracy: 0.992\n",
            "[34,   300/  417] train loss: 3.101 train accuracy: 0.992\n",
            "[34,   400/  417] train loss: 3.269 train accuracy: 0.992\n",
            "[35,   100/  417] train loss: 3.122 train accuracy: 0.984\n",
            "[35,   200/  417] train loss: 3.206 train accuracy: 1.000\n",
            "[35,   300/  417] train loss: 3.183 train accuracy: 0.984\n",
            "[35,   400/  417] train loss: 3.127 train accuracy: 0.977\n",
            "[36,   100/  417] train loss: 3.230 train accuracy: 0.984\n",
            "[36,   200/  417] train loss: 3.519 train accuracy: 0.992\n",
            "[36,   300/  417] train loss: 3.119 train accuracy: 0.984\n",
            "[36,   400/  417] train loss: 3.247 train accuracy: 0.992\n",
            "[37,   100/  417] train loss: 3.475 train accuracy: 0.984\n",
            "[37,   200/  417] train loss: 3.303 train accuracy: 0.992\n",
            "[37,   300/  417] train loss: 3.146 train accuracy: 0.992\n",
            "[37,   400/  417] train loss: 2.933 train accuracy: 0.977\n",
            "[38,   100/  417] train loss: 3.068 train accuracy: 0.984\n",
            "[38,   200/  417] train loss: 3.276 train accuracy: 0.992\n",
            "[38,   300/  417] train loss: 3.052 train accuracy: 0.992\n",
            "[38,   400/  417] train loss: 3.389 train accuracy: 0.961\n",
            "[39,   100/  417] train loss: 3.064 train accuracy: 0.984\n",
            "[39,   200/  417] train loss: 2.970 train accuracy: 0.984\n",
            "[39,   300/  417] train loss: 3.442 train accuracy: 0.992\n",
            "[39,   400/  417] train loss: 3.153 train accuracy: 0.984\n",
            "[40,   100/  417] train loss: 2.969 train accuracy: 0.992\n",
            "[40,   200/  417] train loss: 3.214 train accuracy: 0.992\n",
            "[40,   300/  417] train loss: 3.147 train accuracy: 0.984\n",
            "[40,   400/  417] train loss: 3.061 train accuracy: 1.000\n",
            "[41,   100/  417] train loss: 3.202 train accuracy: 1.000\n",
            "[41,   200/  417] train loss: 3.056 train accuracy: 0.992\n",
            "[41,   300/  417] train loss: 3.359 train accuracy: 0.984\n",
            "[41,   400/  417] train loss: 2.961 train accuracy: 0.992\n",
            "[42,   100/  417] train loss: 3.388 train accuracy: 0.977\n",
            "[42,   200/  417] train loss: 3.016 train accuracy: 0.992\n",
            "[42,   300/  417] train loss: 2.994 train accuracy: 1.000\n",
            "[42,   400/  417] train loss: 3.323 train accuracy: 1.000\n",
            "[43,   100/  417] train loss: 3.151 train accuracy: 1.000\n",
            "[43,   200/  417] train loss: 3.135 train accuracy: 1.000\n",
            "[43,   300/  417] train loss: 3.352 train accuracy: 0.984\n",
            "[43,   400/  417] train loss: 3.125 train accuracy: 0.992\n",
            "[44,   100/  417] train loss: 3.031 train accuracy: 1.000\n",
            "[44,   200/  417] train loss: 3.026 train accuracy: 1.000\n",
            "[44,   300/  417] train loss: 3.125 train accuracy: 1.000\n",
            "[44,   400/  417] train loss: 3.190 train accuracy: 0.984\n",
            "[45,   100/  417] train loss: 3.127 train accuracy: 0.984\n",
            "[45,   200/  417] train loss: 2.809 train accuracy: 0.992\n",
            "[45,   300/  417] train loss: 2.872 train accuracy: 1.000\n",
            "[45,   400/  417] train loss: 3.144 train accuracy: 0.969\n",
            "[46,   100/  417] train loss: 3.161 train accuracy: 0.969\n",
            "[46,   200/  417] train loss: 3.302 train accuracy: 1.000\n",
            "[46,   300/  417] train loss: 3.180 train accuracy: 0.992\n",
            "[46,   400/  417] train loss: 3.201 train accuracy: 0.977\n",
            "[47,   100/  417] train loss: 3.113 train accuracy: 0.984\n",
            "[47,   200/  417] train loss: 3.136 train accuracy: 1.000\n",
            "[47,   300/  417] train loss: 3.384 train accuracy: 0.992\n",
            "[47,   400/  417] train loss: 3.341 train accuracy: 0.984\n",
            "[48,   100/  417] train loss: 3.525 train accuracy: 0.992\n",
            "[48,   200/  417] train loss: 3.152 train accuracy: 0.992\n",
            "[48,   300/  417] train loss: 2.919 train accuracy: 0.984\n",
            "[48,   400/  417] train loss: 3.060 train accuracy: 1.000\n",
            "[49,   100/  417] train loss: 3.238 train accuracy: 0.977\n",
            "[49,   200/  417] train loss: 3.281 train accuracy: 0.977\n",
            "[49,   300/  417] train loss: 3.202 train accuracy: 0.977\n",
            "[49,   400/  417] train loss: 3.031 train accuracy: 0.992\n",
            "[50,   100/  417] train loss: 3.264 train accuracy: 1.000\n",
            "[50,   200/  417] train loss: 3.164 train accuracy: 0.992\n",
            "[50,   300/  417] train loss: 3.067 train accuracy: 1.000\n",
            "[50,   400/  417] train loss: 3.291 train accuracy: 0.984\n",
            "[51,   100/  417] train loss: 3.427 train accuracy: 1.000\n",
            "[51,   200/  417] train loss: 2.845 train accuracy: 0.977\n",
            "[51,   300/  417] train loss: 3.109 train accuracy: 1.000\n",
            "[51,   400/  417] train loss: 3.143 train accuracy: 0.984\n",
            "[52,   100/  417] train loss: 3.054 train accuracy: 0.984\n",
            "[52,   200/  417] train loss: 2.938 train accuracy: 0.984\n",
            "[52,   300/  417] train loss: 3.008 train accuracy: 0.984\n",
            "[52,   400/  417] train loss: 2.993 train accuracy: 0.992\n",
            "[53,   100/  417] train loss: 2.781 train accuracy: 1.000\n",
            "[53,   200/  417] train loss: 3.031 train accuracy: 0.992\n",
            "[53,   300/  417] train loss: 3.004 train accuracy: 1.000\n",
            "[53,   400/  417] train loss: 3.065 train accuracy: 0.984\n",
            "[54,   100/  417] train loss: 3.022 train accuracy: 0.992\n",
            "[54,   200/  417] train loss: 3.158 train accuracy: 0.992\n",
            "[54,   300/  417] train loss: 2.826 train accuracy: 0.992\n",
            "[54,   400/  417] train loss: 3.276 train accuracy: 0.984\n",
            "[55,   100/  417] train loss: 3.427 train accuracy: 0.984\n",
            "[55,   200/  417] train loss: 3.228 train accuracy: 0.984\n",
            "[55,   300/  417] train loss: 2.814 train accuracy: 0.992\n",
            "[55,   400/  417] train loss: 3.011 train accuracy: 0.992\n",
            "[56,   100/  417] train loss: 3.186 train accuracy: 0.992\n",
            "[56,   200/  417] train loss: 3.177 train accuracy: 1.000\n",
            "[56,   300/  417] train loss: 3.386 train accuracy: 0.992\n",
            "[56,   400/  417] train loss: 3.018 train accuracy: 0.992\n",
            "[57,   100/  417] train loss: 3.177 train accuracy: 1.000\n",
            "[57,   200/  417] train loss: 3.183 train accuracy: 1.000\n",
            "[57,   300/  417] train loss: 3.222 train accuracy: 0.984\n",
            "[57,   400/  417] train loss: 2.989 train accuracy: 0.977\n",
            "[58,   100/  417] train loss: 3.358 train accuracy: 0.984\n",
            "[58,   200/  417] train loss: 2.815 train accuracy: 0.984\n",
            "[58,   300/  417] train loss: 3.040 train accuracy: 1.000\n",
            "[58,   400/  417] train loss: 3.010 train accuracy: 0.977\n",
            "[59,   100/  417] train loss: 3.159 train accuracy: 0.969\n",
            "[59,   200/  417] train loss: 3.047 train accuracy: 0.984\n",
            "[59,   300/  417] train loss: 2.858 train accuracy: 0.992\n",
            "[59,   400/  417] train loss: 3.089 train accuracy: 0.992\n",
            "[60,   100/  417] train loss: 3.672 train accuracy: 0.992\n",
            "[60,   200/  417] train loss: 3.209 train accuracy: 1.000\n",
            "[60,   300/  417] train loss: 3.114 train accuracy: 0.977\n",
            "[60,   400/  417] train loss: 2.907 train accuracy: 0.969\n"
          ]
        }
      ],
      "source": [
        "temperatures = [10]\n",
        "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
        "# loss = alpha * st + (1 - alpha) * tt\n",
        "alphas = [0.5]\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    student_net = StudentNetwork()\n",
        "    student_net = student_net.to(fast_device)\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "                                                                train_val_no_one_loader, None, \n",
        "                                                                print_every=print_every, \n",
        "                                                                fast_device=fast_device)\n",
        "    save_path = checkpoints_path_student + hparamToString(hparam) + '_no_one_distillation_final.tar'\n",
        "    torch.save({'results' : results_distill[hparam_tuple], \n",
        "            'model_state_dict' : student_net.state_dict(), \n",
        "            'epoch' : num_epochs}, save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTvKr-sCV5LG"
      },
      "source": [
        "## Calculate student test accuracy with only one in it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kClIhqR0V5LH",
        "outputId": "c892c89d-aaf2-4e3f-d7b3-d17e9168a52c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "student test accuracy (w distillation):  0.9850220264317181\n"
          ]
        }
      ],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_only_one_loader, fast_device)\n",
        "print('student test accuracy (w distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viage72rWRoJ"
      },
      "source": [
        "## Calculate student test accuracy without one in it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHKkRJcoWRoK",
        "outputId": "8c4a6fce-b03d-4be4-df55-3e8716df839a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "student test accuracy (w distillation):  0.9825155104342922\n"
          ]
        }
      ],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_no_one_loader, fast_device)\n",
        "print('student test accuracy (w distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2s11bjavMFE"
      },
      "source": [
        "# Student training without digit two ground truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJwtbVYDvMFE"
      },
      "source": [
        "## Dataloader without digit two"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9sbazE3vMFE"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Student trained without data augmentation\n",
        "transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.5], [0.5])\n",
        "                ]\n",
        "            )\n",
        "\n",
        "train_val_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=True, \n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=False, \n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "num_train = int(1.0 * len(train_val_dataset) * 95 / 100)\n",
        "num_val = len(train_val_dataset) - num_train\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
        "\n",
        "batch_size = 128\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyUzwdRfvMFE"
      },
      "outputs": [],
      "source": [
        "i = -1\n",
        "indices_list = []\n",
        "for img, index in train_val_dataset:\n",
        "    i += 1\n",
        "    if  index != 2:\n",
        "        # print(i, \" index is not one\")\n",
        "        indices_list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgAzxp70vMFE"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "train_val_no_two_dataset = data_utils.Subset(train_val_dataset, indices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_Z-6_l5TZpz"
      },
      "outputs": [],
      "source": [
        "i = -1\n",
        "indices_list = []\n",
        "for img, index in train_val_dataset:\n",
        "    i += 1\n",
        "    if  index == 2:\n",
        "        # print(i, \" index is not one\")\n",
        "        indices_list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYq0XtChTbaY"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "train_val_only_two_dataset = data_utils.Subset(train_val_dataset, indices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdsGFTs8vMFF"
      },
      "outputs": [],
      "source": [
        "i = -1\n",
        "indices_list = []\n",
        "for img, index in test_dataset:\n",
        "    i += 1\n",
        "    if  index != 2:\n",
        "        # print(i, \" index is not one\")\n",
        "        indices_list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W14SQFWyvMFF"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "test_no_two_dataset = data_utils.Subset(test_dataset, indices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu7Xl4PCTfFp"
      },
      "outputs": [],
      "source": [
        "i = -1\n",
        "indices_list = []\n",
        "for img, index in test_dataset:\n",
        "    i += 1\n",
        "    if  index == 2:\n",
        "        # print(i, \" index is not one\")\n",
        "        indices_list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoKDX9ZmTegy"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "test_only_two_dataset = data_utils.Subset(test_dataset, indices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwDPJ3NYvMFF"
      },
      "outputs": [],
      "source": [
        "train_val_no_two_loader = torch.utils.data.DataLoader(train_val_no_two_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_no_two_loader = torch.utils.data.DataLoader(test_no_two_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rejAzBoxTqE8"
      },
      "outputs": [],
      "source": [
        "train_val_only_two_loader = torch.utils.data.DataLoader(train_val_only_two_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_only_two_loader = torch.utils.data.DataLoader(test_only_two_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DavNBhPvMFF"
      },
      "source": [
        "## Train student without distillation without two (T=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzMsxBLFvMFF"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60\n",
        "print_every = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZtD4RzyvMFF",
        "outputId": "d7c1cc25-4558-403f-f372-8b22d7a419d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=1, alpha=0.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
            "[1,   100/  423] train loss: 0.361 train accuracy: 0.867\n",
            "[1,   200/  423] train loss: 0.323 train accuracy: 0.898\n",
            "[1,   300/  423] train loss: 0.171 train accuracy: 0.961\n",
            "[1,   400/  423] train loss: 0.302 train accuracy: 0.914\n",
            "[2,   100/  423] train loss: 0.177 train accuracy: 0.961\n",
            "[2,   200/  423] train loss: 0.271 train accuracy: 0.938\n",
            "[2,   300/  423] train loss: 0.163 train accuracy: 0.945\n",
            "[2,   400/  423] train loss: 0.217 train accuracy: 0.922\n",
            "[3,   100/  423] train loss: 0.200 train accuracy: 0.930\n",
            "[3,   200/  423] train loss: 0.146 train accuracy: 0.961\n",
            "[3,   300/  423] train loss: 0.089 train accuracy: 0.977\n",
            "[3,   400/  423] train loss: 0.106 train accuracy: 0.977\n",
            "[4,   100/  423] train loss: 0.171 train accuracy: 0.953\n",
            "[4,   200/  423] train loss: 0.109 train accuracy: 0.953\n",
            "[4,   300/  423] train loss: 0.166 train accuracy: 0.953\n",
            "[4,   400/  423] train loss: 0.098 train accuracy: 0.977\n",
            "[5,   100/  423] train loss: 0.184 train accuracy: 0.953\n",
            "[5,   200/  423] train loss: 0.112 train accuracy: 0.969\n",
            "[5,   300/  423] train loss: 0.132 train accuracy: 0.953\n",
            "[5,   400/  423] train loss: 0.064 train accuracy: 0.992\n",
            "[6,   100/  423] train loss: 0.153 train accuracy: 0.945\n",
            "[6,   200/  423] train loss: 0.093 train accuracy: 0.977\n",
            "[6,   300/  423] train loss: 0.073 train accuracy: 0.977\n",
            "[6,   400/  423] train loss: 0.041 train accuracy: 0.992\n",
            "[7,   100/  423] train loss: 0.104 train accuracy: 0.984\n",
            "[7,   200/  423] train loss: 0.090 train accuracy: 0.977\n",
            "[7,   300/  423] train loss: 0.022 train accuracy: 0.992\n",
            "[7,   400/  423] train loss: 0.049 train accuracy: 0.992\n",
            "[8,   100/  423] train loss: 0.092 train accuracy: 0.984\n",
            "[8,   200/  423] train loss: 0.052 train accuracy: 0.977\n",
            "[8,   300/  423] train loss: 0.093 train accuracy: 0.969\n",
            "[8,   400/  423] train loss: 0.040 train accuracy: 0.984\n",
            "[9,   100/  423] train loss: 0.048 train accuracy: 0.984\n",
            "[9,   200/  423] train loss: 0.080 train accuracy: 0.977\n",
            "[9,   300/  423] train loss: 0.130 train accuracy: 0.969\n",
            "[9,   400/  423] train loss: 0.051 train accuracy: 0.984\n",
            "[10,   100/  423] train loss: 0.067 train accuracy: 0.984\n",
            "[10,   200/  423] train loss: 0.057 train accuracy: 0.984\n",
            "[10,   300/  423] train loss: 0.114 train accuracy: 0.984\n",
            "[10,   400/  423] train loss: 0.038 train accuracy: 0.992\n",
            "[11,   100/  423] train loss: 0.037 train accuracy: 0.984\n",
            "[11,   200/  423] train loss: 0.041 train accuracy: 1.000\n",
            "[11,   300/  423] train loss: 0.054 train accuracy: 0.977\n",
            "[11,   400/  423] train loss: 0.034 train accuracy: 0.992\n",
            "[12,   100/  423] train loss: 0.049 train accuracy: 0.984\n",
            "[12,   200/  423] train loss: 0.036 train accuracy: 0.992\n",
            "[12,   300/  423] train loss: 0.040 train accuracy: 0.984\n",
            "[12,   400/  423] train loss: 0.050 train accuracy: 0.984\n",
            "[13,   100/  423] train loss: 0.020 train accuracy: 1.000\n",
            "[13,   200/  423] train loss: 0.065 train accuracy: 0.969\n",
            "[13,   300/  423] train loss: 0.054 train accuracy: 0.992\n",
            "[13,   400/  423] train loss: 0.019 train accuracy: 1.000\n",
            "[14,   100/  423] train loss: 0.066 train accuracy: 0.984\n",
            "[14,   200/  423] train loss: 0.059 train accuracy: 0.984\n",
            "[14,   300/  423] train loss: 0.076 train accuracy: 0.977\n",
            "[14,   400/  423] train loss: 0.040 train accuracy: 0.984\n",
            "[15,   100/  423] train loss: 0.041 train accuracy: 0.984\n",
            "[15,   200/  423] train loss: 0.053 train accuracy: 0.977\n",
            "[15,   300/  423] train loss: 0.089 train accuracy: 0.969\n",
            "[15,   400/  423] train loss: 0.045 train accuracy: 0.992\n",
            "[16,   100/  423] train loss: 0.038 train accuracy: 0.992\n",
            "[16,   200/  423] train loss: 0.015 train accuracy: 1.000\n",
            "[16,   300/  423] train loss: 0.047 train accuracy: 0.992\n",
            "[16,   400/  423] train loss: 0.043 train accuracy: 0.984\n",
            "[17,   100/  423] train loss: 0.024 train accuracy: 1.000\n",
            "[17,   200/  423] train loss: 0.084 train accuracy: 0.977\n",
            "[17,   300/  423] train loss: 0.033 train accuracy: 0.992\n",
            "[17,   400/  423] train loss: 0.017 train accuracy: 1.000\n",
            "[18,   100/  423] train loss: 0.079 train accuracy: 0.992\n",
            "[18,   200/  423] train loss: 0.045 train accuracy: 0.984\n",
            "[18,   300/  423] train loss: 0.043 train accuracy: 0.984\n",
            "[18,   400/  423] train loss: 0.054 train accuracy: 0.984\n",
            "[19,   100/  423] train loss: 0.021 train accuracy: 1.000\n",
            "[19,   200/  423] train loss: 0.055 train accuracy: 0.977\n",
            "[19,   300/  423] train loss: 0.027 train accuracy: 0.992\n",
            "[19,   400/  423] train loss: 0.027 train accuracy: 1.000\n",
            "[20,   100/  423] train loss: 0.007 train accuracy: 1.000\n",
            "[20,   200/  423] train loss: 0.044 train accuracy: 0.992\n",
            "[20,   300/  423] train loss: 0.030 train accuracy: 0.992\n",
            "[20,   400/  423] train loss: 0.021 train accuracy: 0.992\n",
            "[21,   100/  423] train loss: 0.048 train accuracy: 0.984\n",
            "[21,   200/  423] train loss: 0.044 train accuracy: 0.984\n",
            "[21,   300/  423] train loss: 0.029 train accuracy: 0.992\n",
            "[21,   400/  423] train loss: 0.066 train accuracy: 0.969\n",
            "[22,   100/  423] train loss: 0.051 train accuracy: 0.984\n",
            "[22,   200/  423] train loss: 0.031 train accuracy: 0.984\n",
            "[22,   300/  423] train loss: 0.022 train accuracy: 1.000\n",
            "[22,   400/  423] train loss: 0.060 train accuracy: 0.984\n",
            "[23,   100/  423] train loss: 0.055 train accuracy: 0.984\n",
            "[23,   200/  423] train loss: 0.046 train accuracy: 0.984\n",
            "[23,   300/  423] train loss: 0.007 train accuracy: 1.000\n",
            "[23,   400/  423] train loss: 0.026 train accuracy: 1.000\n",
            "[24,   100/  423] train loss: 0.021 train accuracy: 0.992\n",
            "[24,   200/  423] train loss: 0.025 train accuracy: 1.000\n",
            "[24,   300/  423] train loss: 0.124 train accuracy: 0.984\n",
            "[24,   400/  423] train loss: 0.016 train accuracy: 1.000\n",
            "[25,   100/  423] train loss: 0.023 train accuracy: 0.992\n",
            "[25,   200/  423] train loss: 0.011 train accuracy: 1.000\n",
            "[25,   300/  423] train loss: 0.037 train accuracy: 0.992\n",
            "[25,   400/  423] train loss: 0.058 train accuracy: 0.984\n",
            "[26,   100/  423] train loss: 0.015 train accuracy: 1.000\n",
            "[26,   200/  423] train loss: 0.038 train accuracy: 0.984\n",
            "[26,   300/  423] train loss: 0.029 train accuracy: 0.992\n",
            "[26,   400/  423] train loss: 0.024 train accuracy: 1.000\n",
            "[27,   100/  423] train loss: 0.043 train accuracy: 0.977\n",
            "[27,   200/  423] train loss: 0.018 train accuracy: 0.992\n",
            "[27,   300/  423] train loss: 0.028 train accuracy: 1.000\n",
            "[27,   400/  423] train loss: 0.081 train accuracy: 0.992\n",
            "[28,   100/  423] train loss: 0.022 train accuracy: 0.992\n",
            "[28,   200/  423] train loss: 0.027 train accuracy: 0.992\n",
            "[28,   300/  423] train loss: 0.014 train accuracy: 1.000\n",
            "[28,   400/  423] train loss: 0.014 train accuracy: 0.992\n",
            "[29,   100/  423] train loss: 0.020 train accuracy: 1.000\n",
            "[29,   200/  423] train loss: 0.027 train accuracy: 1.000\n",
            "[29,   300/  423] train loss: 0.027 train accuracy: 0.992\n",
            "[29,   400/  423] train loss: 0.019 train accuracy: 0.992\n",
            "[30,   100/  423] train loss: 0.027 train accuracy: 0.992\n",
            "[30,   200/  423] train loss: 0.010 train accuracy: 1.000\n",
            "[30,   300/  423] train loss: 0.023 train accuracy: 0.992\n",
            "[30,   400/  423] train loss: 0.045 train accuracy: 0.992\n",
            "[31,   100/  423] train loss: 0.023 train accuracy: 0.992\n",
            "[31,   200/  423] train loss: 0.058 train accuracy: 0.969\n",
            "[31,   300/  423] train loss: 0.035 train accuracy: 0.992\n",
            "[31,   400/  423] train loss: 0.016 train accuracy: 1.000\n",
            "[32,   100/  423] train loss: 0.014 train accuracy: 0.992\n",
            "[32,   200/  423] train loss: 0.016 train accuracy: 1.000\n",
            "[32,   300/  423] train loss: 0.025 train accuracy: 1.000\n",
            "[32,   400/  423] train loss: 0.036 train accuracy: 1.000\n",
            "[33,   100/  423] train loss: 0.022 train accuracy: 1.000\n",
            "[33,   200/  423] train loss: 0.021 train accuracy: 0.992\n",
            "[33,   300/  423] train loss: 0.020 train accuracy: 0.992\n",
            "[33,   400/  423] train loss: 0.025 train accuracy: 0.992\n",
            "[34,   100/  423] train loss: 0.032 train accuracy: 0.992\n",
            "[34,   200/  423] train loss: 0.015 train accuracy: 1.000\n",
            "[34,   300/  423] train loss: 0.015 train accuracy: 1.000\n",
            "[34,   400/  423] train loss: 0.013 train accuracy: 1.000\n",
            "[35,   100/  423] train loss: 0.025 train accuracy: 0.992\n",
            "[35,   200/  423] train loss: 0.008 train accuracy: 1.000\n",
            "[35,   300/  423] train loss: 0.026 train accuracy: 0.992\n",
            "[35,   400/  423] train loss: 0.013 train accuracy: 1.000\n",
            "[36,   100/  423] train loss: 0.021 train accuracy: 1.000\n",
            "[36,   200/  423] train loss: 0.023 train accuracy: 1.000\n",
            "[36,   300/  423] train loss: 0.021 train accuracy: 1.000\n",
            "[36,   400/  423] train loss: 0.028 train accuracy: 0.992\n",
            "[37,   100/  423] train loss: 0.041 train accuracy: 0.992\n",
            "[37,   200/  423] train loss: 0.045 train accuracy: 0.992\n",
            "[37,   300/  423] train loss: 0.009 train accuracy: 1.000\n",
            "[37,   400/  423] train loss: 0.020 train accuracy: 0.992\n",
            "[38,   100/  423] train loss: 0.017 train accuracy: 1.000\n",
            "[38,   200/  423] train loss: 0.006 train accuracy: 1.000\n",
            "[38,   300/  423] train loss: 0.028 train accuracy: 0.977\n",
            "[38,   400/  423] train loss: 0.039 train accuracy: 0.984\n",
            "[39,   100/  423] train loss: 0.020 train accuracy: 1.000\n",
            "[39,   200/  423] train loss: 0.016 train accuracy: 1.000\n",
            "[39,   300/  423] train loss: 0.024 train accuracy: 0.992\n",
            "[39,   400/  423] train loss: 0.022 train accuracy: 1.000\n",
            "[40,   100/  423] train loss: 0.030 train accuracy: 0.992\n",
            "[40,   200/  423] train loss: 0.037 train accuracy: 0.992\n",
            "[40,   300/  423] train loss: 0.027 train accuracy: 1.000\n",
            "[40,   400/  423] train loss: 0.032 train accuracy: 0.992\n",
            "[41,   100/  423] train loss: 0.007 train accuracy: 1.000\n",
            "[41,   200/  423] train loss: 0.016 train accuracy: 1.000\n",
            "[41,   300/  423] train loss: 0.018 train accuracy: 1.000\n",
            "[41,   400/  423] train loss: 0.023 train accuracy: 1.000\n",
            "[42,   100/  423] train loss: 0.023 train accuracy: 1.000\n",
            "[42,   200/  423] train loss: 0.013 train accuracy: 1.000\n",
            "[42,   300/  423] train loss: 0.012 train accuracy: 1.000\n",
            "[42,   400/  423] train loss: 0.012 train accuracy: 1.000\n",
            "[43,   100/  423] train loss: 0.012 train accuracy: 1.000\n",
            "[43,   200/  423] train loss: 0.026 train accuracy: 1.000\n",
            "[43,   300/  423] train loss: 0.019 train accuracy: 1.000\n",
            "[43,   400/  423] train loss: 0.013 train accuracy: 1.000\n",
            "[44,   100/  423] train loss: 0.018 train accuracy: 1.000\n",
            "[44,   200/  423] train loss: 0.011 train accuracy: 1.000\n",
            "[44,   300/  423] train loss: 0.030 train accuracy: 0.992\n",
            "[44,   400/  423] train loss: 0.007 train accuracy: 1.000\n",
            "[45,   100/  423] train loss: 0.011 train accuracy: 1.000\n",
            "[45,   200/  423] train loss: 0.017 train accuracy: 1.000\n",
            "[45,   300/  423] train loss: 0.018 train accuracy: 1.000\n",
            "[45,   400/  423] train loss: 0.009 train accuracy: 1.000\n",
            "[46,   100/  423] train loss: 0.027 train accuracy: 0.992\n",
            "[46,   200/  423] train loss: 0.016 train accuracy: 1.000\n",
            "[46,   300/  423] train loss: 0.011 train accuracy: 1.000\n",
            "[46,   400/  423] train loss: 0.016 train accuracy: 1.000\n",
            "[47,   100/  423] train loss: 0.020 train accuracy: 0.992\n",
            "[47,   200/  423] train loss: 0.022 train accuracy: 0.992\n",
            "[47,   300/  423] train loss: 0.015 train accuracy: 1.000\n",
            "[47,   400/  423] train loss: 0.006 train accuracy: 1.000\n",
            "[48,   100/  423] train loss: 0.027 train accuracy: 0.992\n",
            "[48,   200/  423] train loss: 0.029 train accuracy: 0.992\n",
            "[48,   300/  423] train loss: 0.018 train accuracy: 1.000\n",
            "[48,   400/  423] train loss: 0.010 train accuracy: 1.000\n",
            "[49,   100/  423] train loss: 0.017 train accuracy: 0.992\n",
            "[49,   200/  423] train loss: 0.019 train accuracy: 1.000\n",
            "[49,   300/  423] train loss: 0.009 train accuracy: 1.000\n",
            "[49,   400/  423] train loss: 0.034 train accuracy: 0.984\n",
            "[50,   100/  423] train loss: 0.095 train accuracy: 0.992\n",
            "[50,   200/  423] train loss: 0.016 train accuracy: 0.992\n",
            "[50,   300/  423] train loss: 0.012 train accuracy: 1.000\n",
            "[50,   400/  423] train loss: 0.012 train accuracy: 1.000\n",
            "[51,   100/  423] train loss: 0.039 train accuracy: 0.992\n",
            "[51,   200/  423] train loss: 0.015 train accuracy: 0.992\n",
            "[51,   300/  423] train loss: 0.008 train accuracy: 1.000\n",
            "[51,   400/  423] train loss: 0.072 train accuracy: 0.984\n",
            "[52,   100/  423] train loss: 0.015 train accuracy: 1.000\n",
            "[52,   200/  423] train loss: 0.015 train accuracy: 1.000\n",
            "[52,   300/  423] train loss: 0.018 train accuracy: 1.000\n",
            "[52,   400/  423] train loss: 0.004 train accuracy: 1.000\n",
            "[53,   100/  423] train loss: 0.022 train accuracy: 1.000\n",
            "[53,   200/  423] train loss: 0.008 train accuracy: 1.000\n",
            "[53,   300/  423] train loss: 0.029 train accuracy: 0.992\n",
            "[53,   400/  423] train loss: 0.039 train accuracy: 0.984\n",
            "[54,   100/  423] train loss: 0.034 train accuracy: 0.992\n",
            "[54,   200/  423] train loss: 0.015 train accuracy: 1.000\n",
            "[54,   300/  423] train loss: 0.030 train accuracy: 0.984\n",
            "[54,   400/  423] train loss: 0.013 train accuracy: 1.000\n",
            "[55,   100/  423] train loss: 0.011 train accuracy: 1.000\n",
            "[55,   200/  423] train loss: 0.036 train accuracy: 0.992\n",
            "[55,   300/  423] train loss: 0.011 train accuracy: 1.000\n",
            "[55,   400/  423] train loss: 0.038 train accuracy: 1.000\n",
            "[56,   100/  423] train loss: 0.017 train accuracy: 0.992\n",
            "[56,   200/  423] train loss: 0.018 train accuracy: 1.000\n",
            "[56,   300/  423] train loss: 0.040 train accuracy: 0.992\n",
            "[56,   400/  423] train loss: 0.021 train accuracy: 0.992\n",
            "[57,   100/  423] train loss: 0.012 train accuracy: 1.000\n",
            "[57,   200/  423] train loss: 0.018 train accuracy: 1.000\n",
            "[57,   300/  423] train loss: 0.038 train accuracy: 0.992\n",
            "[57,   400/  423] train loss: 0.011 train accuracy: 0.992\n",
            "[58,   100/  423] train loss: 0.013 train accuracy: 0.992\n",
            "[58,   200/  423] train loss: 0.014 train accuracy: 1.000\n",
            "[58,   300/  423] train loss: 0.010 train accuracy: 1.000\n",
            "[58,   400/  423] train loss: 0.012 train accuracy: 1.000\n",
            "[59,   100/  423] train loss: 0.022 train accuracy: 1.000\n",
            "[59,   200/  423] train loss: 0.012 train accuracy: 1.000\n",
            "[59,   300/  423] train loss: 0.010 train accuracy: 1.000\n",
            "[59,   400/  423] train loss: 0.007 train accuracy: 1.000\n",
            "[60,   100/  423] train loss: 0.019 train accuracy: 0.992\n",
            "[60,   200/  423] train loss: 0.013 train accuracy: 1.000\n",
            "[60,   300/  423] train loss: 0.009 train accuracy: 1.000\n",
            "[60,   400/  423] train loss: 0.013 train accuracy: 1.000\n"
          ]
        }
      ],
      "source": [
        "temperatures = [1]    # temperature for distillation loss\n",
        "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
        "# loss = alpha * st + (1 - alpha) * tt\n",
        "alphas = [0.0]\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "# No dropout used\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    student_net = StudentNetwork()\n",
        "    student_net = student_net.to(fast_device)\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "                                                                train_val_no_two_loader, None, \n",
        "                                                                print_every=print_every, \n",
        "                                                                fast_device=fast_device)\n",
        "    save_path = checkpoints_path_student + hparamToString(hparam) + '_no_two_no_distillation_final.tar'\n",
        "    torch.save({'results' : results_distill[hparam_tuple], \n",
        "                'model_state_dict' : student_net.state_dict(), \n",
        "                'epoch' : num_epochs}, save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rQntIhuvMFF"
      },
      "source": [
        "## Calculate student test accuracy with only two in it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhun027UvMFF",
        "outputId": "14e15a23-facd-44ce-deaf-d86281ec220d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "student test accuracy (w distillation):  0.0\n"
          ]
        }
      ],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_only_two_loader, fast_device)\n",
        "print('student test accuracy (w distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8OaSxG4vMFF"
      },
      "source": [
        "## Calculate student test accuracy without two in it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgdzSKTrvMFF",
        "outputId": "84d0823f-7c6f-4967-8253-ba24152946d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "student test accuracy (w distillation):  0.9811552185548618\n"
          ]
        }
      ],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_no_two_loader, fast_device)\n",
        "print('student test accuracy (w distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tae17ELpXS-w"
      },
      "source": [
        "# Vanilla Distillation with one digit missing (Digit Two)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nCOBu8yXS-w"
      },
      "source": [
        "## Dataloader without digit two"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGxydxnkXS-w"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Student trained without data augmentation\n",
        "transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.5], [0.5])\n",
        "                ]\n",
        "            )\n",
        "\n",
        "train_val_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=True, \n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=False, \n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "num_train = int(1.0 * len(train_val_dataset) * 95 / 100)\n",
        "num_val = len(train_val_dataset) - num_train\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
        "\n",
        "batch_size = 128\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzeQREHWXS-w"
      },
      "outputs": [],
      "source": [
        "i = -1\n",
        "indices_list = []\n",
        "for img, index in train_val_dataset:\n",
        "    i += 1\n",
        "    if  index != 2:\n",
        "        # print(i, \" index is not one\")\n",
        "        indices_list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26cFluWCXS-x"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "train_val_no_two_dataset = data_utils.Subset(train_val_dataset, indices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VDLxybRXS-x"
      },
      "outputs": [],
      "source": [
        "i = -1\n",
        "indices_list = []\n",
        "for img, index in test_dataset:\n",
        "    i += 1\n",
        "    if  index != 2:\n",
        "        # print(i, \" index is not one\")\n",
        "        indices_list.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foSxG7wfXS-x"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "test_no_two_dataset = data_utils.Subset(test_dataset, indices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h7NYk-MXS-x"
      },
      "outputs": [],
      "source": [
        "train_val_no_two_loader = torch.utils.data.DataLoader(train_val_no_two_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_no_two_loader = torch.utils.data.DataLoader(test_no_two_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbcYLXVcXS-x"
      },
      "source": [
        "## Train student without digit two with distillation (T=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1ay1y4gXS-x"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60\n",
        "print_every = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_junK87XS-x",
        "outputId": "c4cabbf9-9326-4d7a-cb2c-693bf4e88277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
            "[1,   100/  423] train loss: 4.568 train accuracy: 0.836\n",
            "[1,   200/  423] train loss: 4.346 train accuracy: 0.930\n",
            "[1,   300/  423] train loss: 3.925 train accuracy: 0.977\n",
            "[1,   400/  423] train loss: 3.970 train accuracy: 0.914\n",
            "[2,   100/  423] train loss: 3.889 train accuracy: 0.969\n",
            "[2,   200/  423] train loss: 3.863 train accuracy: 0.977\n",
            "[2,   300/  423] train loss: 3.961 train accuracy: 0.977\n",
            "[2,   400/  423] train loss: 3.233 train accuracy: 0.953\n",
            "[3,   100/  423] train loss: 3.918 train accuracy: 0.953\n",
            "[3,   200/  423] train loss: 3.750 train accuracy: 0.969\n",
            "[3,   300/  423] train loss: 3.446 train accuracy: 0.984\n",
            "[3,   400/  423] train loss: 3.341 train accuracy: 0.992\n",
            "[4,   100/  423] train loss: 3.753 train accuracy: 0.953\n",
            "[4,   200/  423] train loss: 4.013 train accuracy: 0.961\n",
            "[4,   300/  423] train loss: 3.438 train accuracy: 0.969\n",
            "[4,   400/  423] train loss: 3.304 train accuracy: 0.961\n",
            "[5,   100/  423] train loss: 3.827 train accuracy: 0.922\n",
            "[5,   200/  423] train loss: 3.417 train accuracy: 0.992\n",
            "[5,   300/  423] train loss: 3.507 train accuracy: 0.984\n",
            "[5,   400/  423] train loss: 3.300 train accuracy: 0.977\n",
            "[6,   100/  423] train loss: 3.134 train accuracy: 0.961\n",
            "[6,   200/  423] train loss: 3.037 train accuracy: 0.977\n",
            "[6,   300/  423] train loss: 3.152 train accuracy: 0.992\n",
            "[6,   400/  423] train loss: 2.758 train accuracy: 0.977\n",
            "[7,   100/  423] train loss: 3.925 train accuracy: 0.977\n",
            "[7,   200/  423] train loss: 3.480 train accuracy: 0.977\n",
            "[7,   300/  423] train loss: 3.768 train accuracy: 0.977\n",
            "[7,   400/  423] train loss: 3.021 train accuracy: 0.984\n",
            "[8,   100/  423] train loss: 3.607 train accuracy: 0.984\n",
            "[8,   200/  423] train loss: 3.244 train accuracy: 0.984\n",
            "[8,   300/  423] train loss: 3.194 train accuracy: 0.969\n",
            "[8,   400/  423] train loss: 3.425 train accuracy: 0.969\n",
            "[9,   100/  423] train loss: 3.388 train accuracy: 0.984\n",
            "[9,   200/  423] train loss: 3.260 train accuracy: 0.969\n",
            "[9,   300/  423] train loss: 3.457 train accuracy: 0.969\n",
            "[9,   400/  423] train loss: 3.277 train accuracy: 0.992\n",
            "[10,   100/  423] train loss: 3.345 train accuracy: 0.969\n",
            "[10,   200/  423] train loss: 3.071 train accuracy: 0.992\n",
            "[10,   300/  423] train loss: 3.115 train accuracy: 0.977\n",
            "[10,   400/  423] train loss: 3.315 train accuracy: 0.984\n",
            "[11,   100/  423] train loss: 3.295 train accuracy: 0.977\n",
            "[11,   200/  423] train loss: 3.235 train accuracy: 1.000\n",
            "[11,   300/  423] train loss: 3.210 train accuracy: 0.984\n",
            "[11,   400/  423] train loss: 3.376 train accuracy: 0.992\n",
            "[12,   100/  423] train loss: 3.148 train accuracy: 0.984\n",
            "[12,   200/  423] train loss: 3.069 train accuracy: 0.977\n",
            "[12,   300/  423] train loss: 3.073 train accuracy: 0.992\n",
            "[12,   400/  423] train loss: 3.190 train accuracy: 0.984\n",
            "[13,   100/  423] train loss: 2.928 train accuracy: 1.000\n",
            "[13,   200/  423] train loss: 3.391 train accuracy: 0.984\n",
            "[13,   300/  423] train loss: 3.098 train accuracy: 0.977\n",
            "[13,   400/  423] train loss: 3.357 train accuracy: 1.000\n",
            "[14,   100/  423] train loss: 2.968 train accuracy: 0.984\n",
            "[14,   200/  423] train loss: 3.256 train accuracy: 0.977\n",
            "[14,   300/  423] train loss: 3.377 train accuracy: 0.977\n",
            "[14,   400/  423] train loss: 3.321 train accuracy: 0.984\n",
            "[15,   100/  423] train loss: 3.490 train accuracy: 1.000\n",
            "[15,   200/  423] train loss: 3.866 train accuracy: 0.961\n",
            "[15,   300/  423] train loss: 3.151 train accuracy: 0.945\n",
            "[15,   400/  423] train loss: 3.651 train accuracy: 0.984\n",
            "[16,   100/  423] train loss: 3.506 train accuracy: 0.977\n",
            "[16,   200/  423] train loss: 3.284 train accuracy: 1.000\n",
            "[16,   300/  423] train loss: 3.089 train accuracy: 0.992\n",
            "[16,   400/  423] train loss: 3.340 train accuracy: 0.992\n",
            "[17,   100/  423] train loss: 3.119 train accuracy: 1.000\n",
            "[17,   200/  423] train loss: 3.369 train accuracy: 0.977\n",
            "[17,   300/  423] train loss: 3.030 train accuracy: 1.000\n",
            "[17,   400/  423] train loss: 2.919 train accuracy: 1.000\n",
            "[18,   100/  423] train loss: 3.255 train accuracy: 0.992\n",
            "[18,   200/  423] train loss: 3.201 train accuracy: 0.984\n",
            "[18,   300/  423] train loss: 3.449 train accuracy: 0.984\n",
            "[18,   400/  423] train loss: 3.217 train accuracy: 0.992\n",
            "[19,   100/  423] train loss: 2.857 train accuracy: 1.000\n",
            "[19,   200/  423] train loss: 3.558 train accuracy: 0.992\n",
            "[19,   300/  423] train loss: 3.137 train accuracy: 0.992\n",
            "[19,   400/  423] train loss: 3.345 train accuracy: 1.000\n",
            "[20,   100/  423] train loss: 3.268 train accuracy: 1.000\n",
            "[20,   200/  423] train loss: 3.644 train accuracy: 0.969\n",
            "[20,   300/  423] train loss: 3.478 train accuracy: 0.992\n",
            "[20,   400/  423] train loss: 3.274 train accuracy: 0.992\n",
            "[21,   100/  423] train loss: 3.245 train accuracy: 0.984\n",
            "[21,   200/  423] train loss: 3.189 train accuracy: 0.984\n",
            "[21,   300/  423] train loss: 2.788 train accuracy: 0.984\n",
            "[21,   400/  423] train loss: 3.410 train accuracy: 0.969\n",
            "[22,   100/  423] train loss: 3.051 train accuracy: 0.984\n",
            "[22,   200/  423] train loss: 3.102 train accuracy: 0.992\n",
            "[22,   300/  423] train loss: 2.989 train accuracy: 0.992\n",
            "[22,   400/  423] train loss: 3.488 train accuracy: 0.977\n",
            "[23,   100/  423] train loss: 3.227 train accuracy: 0.977\n",
            "[23,   200/  423] train loss: 3.050 train accuracy: 0.984\n",
            "[23,   300/  423] train loss: 3.025 train accuracy: 1.000\n",
            "[23,   400/  423] train loss: 3.044 train accuracy: 0.992\n",
            "[24,   100/  423] train loss: 3.108 train accuracy: 0.992\n",
            "[24,   200/  423] train loss: 3.440 train accuracy: 0.992\n",
            "[24,   300/  423] train loss: 3.364 train accuracy: 0.977\n",
            "[24,   400/  423] train loss: 3.534 train accuracy: 1.000\n",
            "[25,   100/  423] train loss: 3.362 train accuracy: 0.984\n",
            "[25,   200/  423] train loss: 3.222 train accuracy: 0.992\n",
            "[25,   300/  423] train loss: 3.471 train accuracy: 0.984\n",
            "[25,   400/  423] train loss: 3.595 train accuracy: 0.977\n",
            "[26,   100/  423] train loss: 2.976 train accuracy: 0.992\n",
            "[26,   200/  423] train loss: 3.092 train accuracy: 0.984\n",
            "[26,   300/  423] train loss: 3.425 train accuracy: 0.977\n",
            "[26,   400/  423] train loss: 3.092 train accuracy: 0.969\n",
            "[27,   100/  423] train loss: 3.237 train accuracy: 0.977\n",
            "[27,   200/  423] train loss: 3.100 train accuracy: 1.000\n",
            "[27,   300/  423] train loss: 3.278 train accuracy: 0.977\n",
            "[27,   400/  423] train loss: 3.058 train accuracy: 0.992\n",
            "[28,   100/  423] train loss: 3.181 train accuracy: 0.992\n",
            "[28,   200/  423] train loss: 3.022 train accuracy: 1.000\n",
            "[28,   300/  423] train loss: 3.358 train accuracy: 0.992\n",
            "[28,   400/  423] train loss: 3.350 train accuracy: 0.992\n",
            "[29,   100/  423] train loss: 3.433 train accuracy: 0.977\n",
            "[29,   200/  423] train loss: 2.975 train accuracy: 0.984\n",
            "[29,   300/  423] train loss: 3.237 train accuracy: 0.977\n",
            "[29,   400/  423] train loss: 2.831 train accuracy: 0.992\n",
            "[30,   100/  423] train loss: 3.320 train accuracy: 0.984\n",
            "[30,   200/  423] train loss: 3.445 train accuracy: 1.000\n",
            "[30,   300/  423] train loss: 3.099 train accuracy: 0.992\n",
            "[30,   400/  423] train loss: 3.158 train accuracy: 0.992\n",
            "[31,   100/  423] train loss: 3.116 train accuracy: 1.000\n",
            "[31,   200/  423] train loss: 3.361 train accuracy: 0.984\n",
            "[31,   300/  423] train loss: 3.463 train accuracy: 0.984\n",
            "[31,   400/  423] train loss: 3.042 train accuracy: 1.000\n",
            "[32,   100/  423] train loss: 3.505 train accuracy: 0.992\n",
            "[32,   200/  423] train loss: 3.094 train accuracy: 1.000\n",
            "[32,   300/  423] train loss: 3.214 train accuracy: 1.000\n",
            "[32,   400/  423] train loss: 3.569 train accuracy: 0.977\n",
            "[33,   100/  423] train loss: 2.919 train accuracy: 0.984\n",
            "[33,   200/  423] train loss: 3.238 train accuracy: 1.000\n",
            "[33,   300/  423] train loss: 2.910 train accuracy: 0.992\n",
            "[33,   400/  423] train loss: 3.287 train accuracy: 0.984\n",
            "[34,   100/  423] train loss: 2.798 train accuracy: 0.984\n",
            "[34,   200/  423] train loss: 3.471 train accuracy: 1.000\n",
            "[34,   300/  423] train loss: 3.294 train accuracy: 0.992\n",
            "[34,   400/  423] train loss: 2.867 train accuracy: 1.000\n",
            "[35,   100/  423] train loss: 3.572 train accuracy: 0.992\n",
            "[35,   200/  423] train loss: 3.272 train accuracy: 1.000\n",
            "[35,   300/  423] train loss: 3.197 train accuracy: 0.977\n",
            "[35,   400/  423] train loss: 3.451 train accuracy: 0.992\n",
            "[36,   100/  423] train loss: 3.248 train accuracy: 0.992\n",
            "[36,   200/  423] train loss: 2.968 train accuracy: 0.984\n",
            "[36,   300/  423] train loss: 2.997 train accuracy: 0.992\n",
            "[36,   400/  423] train loss: 3.171 train accuracy: 0.984\n",
            "[37,   100/  423] train loss: 3.427 train accuracy: 0.984\n",
            "[37,   200/  423] train loss: 3.125 train accuracy: 0.977\n",
            "[37,   300/  423] train loss: 2.965 train accuracy: 1.000\n",
            "[37,   400/  423] train loss: 3.255 train accuracy: 0.992\n",
            "[38,   100/  423] train loss: 3.320 train accuracy: 0.992\n",
            "[38,   200/  423] train loss: 3.069 train accuracy: 1.000\n",
            "[38,   300/  423] train loss: 3.417 train accuracy: 0.992\n",
            "[38,   400/  423] train loss: 3.026 train accuracy: 0.977\n",
            "[39,   100/  423] train loss: 2.790 train accuracy: 1.000\n",
            "[39,   200/  423] train loss: 3.319 train accuracy: 0.992\n",
            "[39,   300/  423] train loss: 3.145 train accuracy: 0.984\n",
            "[39,   400/  423] train loss: 3.042 train accuracy: 0.977\n",
            "[40,   100/  423] train loss: 2.855 train accuracy: 0.992\n",
            "[40,   200/  423] train loss: 3.260 train accuracy: 0.984\n",
            "[40,   300/  423] train loss: 3.074 train accuracy: 0.992\n",
            "[40,   400/  423] train loss: 3.287 train accuracy: 0.977\n",
            "[41,   100/  423] train loss: 2.972 train accuracy: 1.000\n",
            "[41,   200/  423] train loss: 2.858 train accuracy: 0.984\n",
            "[41,   300/  423] train loss: 3.178 train accuracy: 1.000\n",
            "[41,   400/  423] train loss: 3.184 train accuracy: 0.984\n",
            "[42,   100/  423] train loss: 3.036 train accuracy: 0.977\n",
            "[42,   200/  423] train loss: 2.941 train accuracy: 1.000\n",
            "[42,   300/  423] train loss: 3.250 train accuracy: 0.992\n",
            "[42,   400/  423] train loss: 2.928 train accuracy: 1.000\n",
            "[43,   100/  423] train loss: 3.068 train accuracy: 1.000\n",
            "[43,   200/  423] train loss: 3.127 train accuracy: 1.000\n",
            "[43,   300/  423] train loss: 3.167 train accuracy: 0.977\n",
            "[43,   400/  423] train loss: 3.111 train accuracy: 1.000\n",
            "[44,   100/  423] train loss: 3.203 train accuracy: 0.992\n",
            "[44,   200/  423] train loss: 3.238 train accuracy: 1.000\n",
            "[44,   300/  423] train loss: 3.149 train accuracy: 0.984\n",
            "[44,   400/  423] train loss: 3.280 train accuracy: 1.000\n",
            "[45,   100/  423] train loss: 3.026 train accuracy: 1.000\n",
            "[45,   200/  423] train loss: 3.144 train accuracy: 1.000\n",
            "[45,   300/  423] train loss: 2.829 train accuracy: 0.992\n",
            "[45,   400/  423] train loss: 3.062 train accuracy: 1.000\n",
            "[46,   100/  423] train loss: 2.945 train accuracy: 0.977\n",
            "[46,   200/  423] train loss: 2.941 train accuracy: 0.984\n",
            "[46,   300/  423] train loss: 3.060 train accuracy: 0.992\n",
            "[46,   400/  423] train loss: 3.432 train accuracy: 0.992\n",
            "[47,   100/  423] train loss: 3.118 train accuracy: 0.977\n",
            "[47,   200/  423] train loss: 3.068 train accuracy: 0.984\n",
            "[47,   300/  423] train loss: 3.166 train accuracy: 0.984\n",
            "[47,   400/  423] train loss: 3.367 train accuracy: 1.000\n",
            "[48,   100/  423] train loss: 3.352 train accuracy: 0.984\n",
            "[48,   200/  423] train loss: 3.306 train accuracy: 0.969\n",
            "[48,   300/  423] train loss: 3.194 train accuracy: 0.992\n",
            "[48,   400/  423] train loss: 3.397 train accuracy: 1.000\n",
            "[49,   100/  423] train loss: 3.129 train accuracy: 1.000\n",
            "[49,   200/  423] train loss: 2.899 train accuracy: 0.984\n",
            "[49,   300/  423] train loss: 3.595 train accuracy: 1.000\n",
            "[49,   400/  423] train loss: 3.157 train accuracy: 0.984\n",
            "[50,   100/  423] train loss: 3.524 train accuracy: 0.977\n",
            "[50,   200/  423] train loss: 3.347 train accuracy: 0.984\n",
            "[50,   300/  423] train loss: 3.203 train accuracy: 0.984\n",
            "[50,   400/  423] train loss: 3.063 train accuracy: 1.000\n",
            "[51,   100/  423] train loss: 2.795 train accuracy: 0.969\n",
            "[51,   200/  423] train loss: 3.413 train accuracy: 0.992\n",
            "[51,   300/  423] train loss: 3.040 train accuracy: 0.992\n",
            "[51,   400/  423] train loss: 3.205 train accuracy: 0.977\n",
            "[52,   100/  423] train loss: 3.498 train accuracy: 0.984\n",
            "[52,   200/  423] train loss: 2.962 train accuracy: 1.000\n",
            "[52,   300/  423] train loss: 2.981 train accuracy: 0.992\n",
            "[52,   400/  423] train loss: 3.195 train accuracy: 1.000\n",
            "[53,   100/  423] train loss: 3.398 train accuracy: 0.977\n",
            "[53,   200/  423] train loss: 3.062 train accuracy: 1.000\n",
            "[53,   300/  423] train loss: 3.090 train accuracy: 0.992\n",
            "[53,   400/  423] train loss: 2.755 train accuracy: 0.984\n",
            "[54,   100/  423] train loss: 2.974 train accuracy: 1.000\n",
            "[54,   200/  423] train loss: 3.380 train accuracy: 0.984\n",
            "[54,   300/  423] train loss: 2.977 train accuracy: 0.992\n",
            "[54,   400/  423] train loss: 3.286 train accuracy: 1.000\n",
            "[55,   100/  423] train loss: 3.034 train accuracy: 1.000\n",
            "[55,   200/  423] train loss: 3.344 train accuracy: 0.984\n",
            "[55,   300/  423] train loss: 3.075 train accuracy: 1.000\n",
            "[55,   400/  423] train loss: 3.078 train accuracy: 0.961\n",
            "[56,   100/  423] train loss: 3.027 train accuracy: 0.992\n",
            "[56,   200/  423] train loss: 3.197 train accuracy: 1.000\n",
            "[56,   300/  423] train loss: 3.256 train accuracy: 0.992\n",
            "[56,   400/  423] train loss: 3.123 train accuracy: 0.992\n",
            "[57,   100/  423] train loss: 2.794 train accuracy: 1.000\n",
            "[57,   200/  423] train loss: 3.316 train accuracy: 1.000\n",
            "[57,   300/  423] train loss: 3.187 train accuracy: 0.961\n",
            "[57,   400/  423] train loss: 3.217 train accuracy: 1.000\n",
            "[58,   100/  423] train loss: 3.516 train accuracy: 1.000\n",
            "[58,   200/  423] train loss: 2.928 train accuracy: 0.992\n",
            "[58,   300/  423] train loss: 3.111 train accuracy: 1.000\n",
            "[58,   400/  423] train loss: 3.225 train accuracy: 0.992\n",
            "[59,   100/  423] train loss: 2.997 train accuracy: 0.992\n",
            "[59,   200/  423] train loss: 2.904 train accuracy: 0.992\n",
            "[59,   300/  423] train loss: 3.094 train accuracy: 1.000\n",
            "[59,   400/  423] train loss: 3.171 train accuracy: 1.000\n",
            "[60,   100/  423] train loss: 3.129 train accuracy: 0.992\n",
            "[60,   200/  423] train loss: 3.148 train accuracy: 0.984\n",
            "[60,   300/  423] train loss: 3.076 train accuracy: 0.992\n",
            "[60,   400/  423] train loss: 2.929 train accuracy: 0.992\n"
          ]
        }
      ],
      "source": [
        "temperatures = [10]\n",
        "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
        "# loss = alpha * st + (1 - alpha) * tt\n",
        "alphas = [0.5]\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    student_net = StudentNetwork()\n",
        "    student_net = student_net.to(fast_device)\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "                                                                train_val_no_two_loader, None, \n",
        "                                                                print_every=print_every, \n",
        "                                                                fast_device=fast_device)\n",
        "    save_path = checkpoints_path_student + hparamToString(hparam) + '_no_two_distillation_final.tar'\n",
        "    torch.save({'results' : results_distill[hparam_tuple], \n",
        "                'model_state_dict' : student_net.state_dict(), \n",
        "                'epoch' : num_epochs}, save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIJimAMnXS-x"
      },
      "source": [
        "## Calculate student test accuracy with only two in it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b0HIvV_LXS-x",
        "outputId": "50e8d8c2-e226-425a-f6f7-879d746e3f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "student test accuracy (w distillation):  0.9273255813953488\n"
          ]
        }
      ],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_only_two_loader, fast_device)\n",
        "print('student test accuracy (w distillation): ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAeFUydxXS-x"
      },
      "source": [
        "## Calculate student test accuracy without two in it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ersDF1oMXS-x",
        "outputId": "5571e1ec-189b-4d09-e4a0-ce57de43f5a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "student test accuracy (w distillation):  0.9850579839429081\n"
          ]
        }
      ],
      "source": [
        "# Calculate student test accuracy\n",
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, test_no_two_loader, fast_device)\n",
        "print('student test accuracy (w distillation): ', test_accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "S6H_dU4IZ8yM",
        "tIrYpWa2aB1r",
        "60fK42rvaMgH",
        "9HXQ9Iu1abae",
        "wbgMENMOagyY",
        "MKVMNxRjZz-G",
        "r06JG661a-44",
        "6OGeihmzbCIS",
        "5S1btnKMbH08",
        "WzFCzR3cb2qh",
        "vZ1fVVKFoFuT",
        "RjgKyPVSoQe-",
        "z-VGPYsKoUJH",
        "3c1F3E5toUJI",
        "Qxd-KnBMoqOR",
        "1s-u0B-qoqOS",
        "Pbk1fSbaorhG"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}